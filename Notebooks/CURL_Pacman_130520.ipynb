{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CURL_Pacman_110520.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1UROvHOI-JmTk7LtcSI-pTs9Xw-XN9fnc",
      "authorship_tag": "ABX9TyM79QP9p1N73jGOJM+QsHHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Model-based-RL/blob/master/CURL_Pacman_130520.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57XVXKX0pUf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hdnkq3rcJNF",
        "colab_type": "text"
      },
      "source": [
        "# Used to save Pacman video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp0jzlXIcFfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fss3NXoMcIjw",
        "colab_type": "code",
        "outputId": "d025f322-5ec6-4461-ca46-dfd9fec6739e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!apt-get install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (46.1.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4jLAGgyjflE",
        "colab_type": "text"
      },
      "source": [
        "# Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rD40Izgp1JQ",
        "colab_type": "code",
        "outputId": "09cd2a92-77c1-4f4d-b164-da671b4fa27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "#!pip install git+git://github.com/mila-iqia/atari-representation-learning.git\n",
        "#!pip install git+git://github.com/ankeshanand/pytorch-a2c-ppo-acktr-gail\n",
        "!pip install git+git://github.com/openai/baselines\n",
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/openai/baselines\n",
            "  Cloning git://github.com/openai/baselines to /tmp/pip-req-build-jcf6gh6p\n",
            "  Running command git clone -q git://github.com/openai/baselines /tmp/pip-req-build-jcf6gh6p\n",
            "Requirement already satisfied (use --upgrade to upgrade): baselines==0.1.6 from git+git://github.com/openai/baselines in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: gym<0.16.0,>=0.15.4 in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (0.15.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (0.14.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.16.0)\n",
            "Building wheels for collected packages: baselines\n",
            "  Building wheel for baselines (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for baselines: filename=baselines-0.1.6-cp36-none-any.whl size=220664 sha256=87b88d82726b51bad970753bdb0996338a514d55b7fd64f0a6318fe2c8adfe7d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hnxw_9wc/wheels/42/1c/91/28314e0cd1d2cc57cf8dd18b20c4c9a0f39ae518adc13caf24\n",
            "Successfully built baselines\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.8.36)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.0)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.14.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: gql==0.2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.2.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.4.5.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: graphql-core<2,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (1.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNPbRVOCqA3q",
        "colab_type": "code",
        "outputId": "24f384a4-1013-4830-bdbf-09e1c3cb2bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!wandb login #############"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI287_Yjxn3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from __future__ import print_function\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "import wandb\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from Contrastive_loss_Pacman.custom_wrappers import custom_wrapper\n",
        "from Contrastive_loss_Pacman.encoder import make_encoder\n",
        "from Contrastive_loss_Pacman.EarlyStopping import EarlyStopping_loss\n",
        "from Contrastive_loss_Pacman.GeneralFunctions import General_functions\n",
        "from Contrastive_loss_Pacman.utils import make_dir, random_crop,center_crop_image, soft_update_params, weight_init\n",
        "from torch.autograd import Variable\n",
        "from Contrastive_loss_Pacman.DataCollection import Data_collection\n",
        "from Contrastive_loss_Pacman.models import CURL, Dynamics_model\n",
        "import gym\n",
        "import time\n",
        "\n",
        "# Needed to create dataloaders\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDaFHhxLacNp",
        "colab_type": "text"
      },
      "source": [
        "# CURL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc15PakPabSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CurlAgent(object):\n",
        "    ''' CURL representation learning'''\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_shape,\n",
        "        device,\n",
        "        hidden_dim = 256,\n",
        "        output_dim = 2,\n",
        "        encoder_feature_dim = 50,\n",
        "        encoder_lr = 1e-3,\n",
        "        encoder_tau = 0.005,\n",
        "        num_layers=4,\n",
        "        num_filters = 32,\n",
        "        cpc_update_freq=1,\n",
        "        dyn_update_freq= 2,\n",
        "        encoder_update_freq = 2,\n",
        "        detach_encoder=True,\n",
        "    ):\n",
        "        self.device = device\n",
        "        self.cpc_update_freq = cpc_update_freq\n",
        "        self.dyn_update_freq = dyn_update_freq\n",
        "        self.image_size = obs_shape[-2] # Changed this to the numpy dimension\n",
        "        self.detach_encoder = detach_encoder\n",
        "        self.encoder_update_freq = encoder_update_freq\n",
        "        self.encoder_tau = encoder_tau\n",
        "        self.epoch_step = 0\n",
        "        self.pretrain_epoch_step = 0\n",
        "        \n",
        "        self.CURL = CURL(obs_shape, encoder_feature_dim,\n",
        "                         encoder_feature_dim, num_layers, num_filters).to(self.device)\n",
        "        \n",
        "        self.Model = Dynamics_model(obs_shape,hidden_dim,output_dim,encoder_feature_dim,num_layers,num_filters).to(self.device)\n",
        "\n",
        "        # tie encoders between and CURL and dynamics predictor - VERY IMPORTANT-  CAN REMOVE IF I WANT SEPARATE NETWORKS\n",
        "        if self.detach_encoder: # If the encoder for the dynamics network is not being updated , then we only want to use the contrastive loss to update the network\n",
        "            self.Model.encoder.copy_conv_weights_from(self.CURL.encoder) \n",
        "\n",
        "        self.cpc_optimizer = torch.optim.Adam(\n",
        "                self.CURL.parameters(), lr=encoder_lr\n",
        "            )\n",
        "        \n",
        "        self.dynamics_optimizer = torch.optim.Adam(self.Model.parameters(), lr= encoder_lr)\n",
        "\n",
        "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "        self.MSE_loss = nn.MSELoss() # Nawid - Added this loss for the prediction\n",
        "        self.train()\n",
        "    \n",
        "    def train(self, training = True):\n",
        "        self.training = training\n",
        "        self.CURL.train(training)\n",
        "        self.Model.train(training)\n",
        "\n",
        "    def update(self, train_dataloader,val_dataloader,early_stopper):\n",
        "        #torch.cuda.empty_cache() # Releases cache so the GPU has more memory\n",
        "        if early_stopper.early_stop:\n",
        "            print('early stopping')\n",
        "            return\n",
        "\n",
        "        for step, (obs, actions, state_change, cpc_kwargs) in enumerate(train_dataloader):\n",
        "        \n",
        "            if step % self.encoder_update_freq == 0:\n",
        "                soft_update_params(\n",
        "                    self.CURL.encoder, self.CURL.encoder_target,\n",
        "                    self.encoder_tau\n",
        "                )\n",
        "        \n",
        "            if step % self.cpc_update_freq == 0:            \n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                self.update_cpc(obs_anchor, obs_pos,cpc_kwargs) # Nawid -  Performs the contrastive loss I believe\n",
        "        \n",
        "            if step % self.dyn_update_freq ==0:    \n",
        "                self.update_dynamics(obs, actions,state_change)\n",
        "\n",
        "        \n",
        "        self.validation(val_dataloader,early_stopper)\n",
        "    \n",
        "\n",
        "    def update_cpc(self, obs_anchor, obs_pos, cpc_kwargs):\n",
        "        obs_anchor, obs_pos = obs_anchor.float().to(self.device), obs_pos.float().to(self.device)\n",
        "        z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "        z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "\n",
        "        logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "        labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "        loss = self.cross_entropy_loss(logits, labels)\n",
        "        wandb.log({'Contrastive Training loss':loss.item()})\n",
        "\n",
        "        self.cpc_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        self.cpc_optimizer.step()  # Nawid - Used to update the cpc\n",
        "    \n",
        "    def update_dynamics(self, obs,actions, labels):\n",
        "        obs, actions, labels = obs.float().to(self.device), actions.float().to(self.device), labels.float().to(self.device)\n",
        "\n",
        "        prediction = self.Model(obs,actions,detach_encoder=self.detach_encoder) # gradient not backpropagated to the encoder\n",
        "        prediction_loss = self.MSE_loss(prediction,labels)\n",
        "        wandb.log({'Dynamics Training loss':prediction_loss.item()}) #  Need to use .item otherwise the loss will still be kept which will reduce the memory on the GPU\n",
        "        \n",
        "        self.dynamics_optimizer.zero_grad()\n",
        "        prediction_loss.backward()\n",
        "        self.dynamics_optimizer.step()\n",
        "\n",
        "    def validation(self, dataloader,early_stopper):\n",
        "        epoch_contrastive_loss = 0\n",
        "        epoch_dynamics_loss = 0 \n",
        "        self.Model.eval()\n",
        "        self.CURL.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (obses, actions, state_change, cpc_kwargs) in enumerate(dataloader):\n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                obses, obs_anchor,obs_pos = obses.float().to(self.device), obs_anchor.float().to(self.device), obs_pos.float().to(self.device)\n",
        "                actions, state_change = actions.to(self.device), state_change.to(self.device)\n",
        "\n",
        "                z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "                z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "                logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "                labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "                loss = self.cross_entropy_loss(logits, labels)\n",
        "                epoch_contrastive_loss += loss.item()\n",
        "                \n",
        "                val_prediction = self.Model(obs_anchor,actions,detach_encoder=self.detach_encoder) # gradient not backpropagated to the encoder\n",
        "                val_prediction_loss = self.MSE_loss(val_prediction,state_change)\n",
        "                epoch_dynamics_loss += val_prediction_loss.item()\n",
        "            \n",
        "            average_epoch_contrastive_loss = epoch_contrastive_loss/i\n",
        "            average_epoch_dynamics_loss = epoch_dynamics_loss/i            \n",
        "            \n",
        "            self.epoch_step += 1 # increase epoch counter\n",
        "            wandb.log({'Contrastive Validation loss':average_epoch_contrastive_loss,'Dynamics Validation loss':average_epoch_dynamics_loss,'epoch': self.epoch_step})\n",
        "            print('epoch:', self.epoch_step)\n",
        "            print('val prediction:', val_prediction[0:20]) #  batch of the val prediction is the size of the last batch so it will be what is leftover till the set is complete\n",
        "            print('state change:',state_change[0:20])\n",
        "\n",
        "            #early_stopper(average_epoch_dynamics_loss,self.Model,self.dynamics_optimizer)\n",
        "\n",
        "        self.train()\n",
        "\n",
        "    \n",
        "    def pretrain(self,train_dataloader,val_dataloader, pretrain_early_stopper):\n",
        "        if pretrain_early_stopper.early_stop:\n",
        "            print('early stopping pretrained model')\n",
        "            return\n",
        "\n",
        "        for pretrain_step, (_, _, state_change, cpc_kwargs) in enumerate(train_dataloader):\n",
        "            if pretrain_step % self.encoder_update_freq == 0:\n",
        "                soft_update_params(\n",
        "                    self.CURL.encoder, self.CURL.encoder_target,\n",
        "                    self.encoder_tau\n",
        "                )\n",
        "\n",
        "            if pretrain_step % self.cpc_update_freq == 0:            \n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                self.update_cpc(obs_anchor, obs_pos,cpc_kwargs) # Nawid -  Performs the contrastive loss I believe\n",
        "        \n",
        "        \n",
        "        self.pretrain_val(val_dataloader,pretrain_early_stopper)\n",
        "    \n",
        "    def pretrain_val(self, dataloader,pretrain_early_stopper):\n",
        "        epoch_pretrain_contrastive_loss = 0 \n",
        "        self.CURL.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (_, _, _, cpc_kwargs) in enumerate(dataloader):\n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                obs_anchor,obs_pos = obs_anchor.float().to(self.device), obs_pos.float().to(self.device)\n",
        "\n",
        "                z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "                z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "                logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "                labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "                loss = self.cross_entropy_loss(logits, labels)\n",
        "                epoch_pretrain_contrastive_loss += loss.item()\n",
        "                \n",
        "            self.pretrain_epoch_step += 1 \n",
        "            average_epoch_pretrain_contrastive_loss = epoch_pretrain_contrastive_loss/i                        \n",
        "            self.pretrain_epoch_step += 1 # increase epoch counter\n",
        "            wandb.log({'Pretrain Contrastive Validation loss':average_epoch_pretrain_contrastive_loss,'pretrain epoch': self.pretrain_epoch_step})\n",
        "            pretrain_early_stopper(average_epoch_pretrain_contrastive_loss,self.CURL,self.cpc_optimizer)\n",
        "\n",
        "def make_agent(obs_shape, device, dict_info):\n",
        "    return CurlAgent(\n",
        "        obs_shape = obs_shape,\n",
        "        device = device,\n",
        "        output_dim = dict_info['state_space'],\n",
        "        encoder_update_freq =dict_info['encoder_update_freq'],\n",
        "        dyn_update_freq =dict_info['dynamics_update_freq'],\n",
        "        encoder_feature_dim = dict_info['encoder_feature_dim'],\n",
        "        encoder_lr = dict_info['encoder_lr'],\n",
        "        encoder_tau = dict_info['encoder_tau'],\n",
        "        num_layers = dict_info['num_layers'],\n",
        "        num_filters = dict_info['num_filters'],\n",
        "        detach_encoder =dict_info['detach_dyn_encoder']\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4SvnJeJUgM",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHK7nCaJT-J",
        "colab_type": "code",
        "outputId": "30c5fd4c-cfb5-47ed-9506-f21639000192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ENV_NAME = 'MsPacmanDeterministic-v4'\n",
        "n_actions = 4 #9 - Nawid - Change to 5 actions as the 4 other actions are simply copies of the other actions, therefore 5 actions should lower the amount of data needed.\n",
        "no_agents = 2\n",
        "output_dim = no_agents*2\n",
        "parse_dict= {'pre_transform_image_size':100,\n",
        "             'image_size':84,\n",
        "             'frame_stack':4,\n",
        "             'state_space':output_dim,\n",
        "             'train_capacity_1':100000,\n",
        "             'train_capacity_2':25000,\n",
        "             'train_capacity_3':25000,\n",
        "             'val_capacity':2000,\n",
        "             'num_train_steps':20000,\n",
        "             'batch_size':256,\n",
        "             'random_crop': True,\n",
        "             'encoder_update_freq':2,\n",
        "             'encoder_feature_dim':50,\n",
        "             'encoder_lr':1e-3,\n",
        "             'encoder_tau':0.05,\n",
        "             'num_layers':4,\n",
        "             'num_filters':32,\n",
        "             'load_trajectories':False,\n",
        "             'grayscale': False,\n",
        "             'load_pretrain_model': False,\n",
        "             'walls_present':False,\n",
        "             'dynamics_update_freq': 2,\n",
        "             'detach_dyn_encoder':True,\n",
        "             'pretrain_model':False,\n",
        "             'save_data':False\n",
        "            }\n",
        "\n",
        "custom_name = str(no_agents)+ '_agents' + '_rand_crop-' +str(parse_dict['random_crop'])  + '_gray-' + str(parse_dict['grayscale']) + '_walls-' +str(parse_dict['walls_present']) + '_detach_encoder-' + str(parse_dict['detach_dyn_encoder']) + '_pretrain-' + str(parse_dict['pretrain_model'])\n",
        "wandb.init(entity=\"nerdk312\",name=custom_name, project=\"Contrastive_learning\",config = parse_dict)\n",
        "\n",
        "possible_positions = np.load('/content/drive/My Drive/MsPacman-data/possible_pacman_positions.npy',allow_pickle=True)\n",
        "preloaded_train_data_1 = '/content/drive/My Drive/MsPacman-data/12-05_18:55_capacity-25000_grayscale-False_walls_present-False'  \n",
        "preloaded_train_data_2 = '/content/drive/My Drive/MsPacman-data/12-05_18:58_capacity-25000_grayscale-False_walls_present-False'\n",
        "preloaded_train_data_3 = '/content/drive/My Drive/MsPacman-data/12-05_19:02_capacity-25000_grayscale-False_walls_present-False'\n",
        "preloaded_val_data = '/content/drive/My Drive/MsPacman-data/12-05_19:05_capacity-20000_grayscale-False_walls_present-False' #'/content/drive/My Drive/MsPacman-data/12-05_12:21_capacity-10000_grayscale-True_walls_present-False' #'/content/drive/My Drive/MsPacman-data/12-05_10:28_capacity-10000_grayscale-True_walls_present-True'   \n",
        "num_pretrain_steps = 5000\n",
        "\n",
        "config = wandb.config\n",
        "if parse_dict['load_trajectories']:\n",
        "    config.loaded_train_trajectories_1 = preloaded_train_data_1\n",
        "    config.loaded_train_trajectories_2 = preloaded_train_data_2\n",
        "    config.loaded_train_trajectories_3 = preloaded_train_data_3\n",
        "    config.loaded_val_trajectories = preloaded_val_data\n",
        "\n",
        "if parse_dict['pretrain_model']:\n",
        "    config.pretrain_steps = num_pretrain_steps \n",
        "\n",
        "if parse_dict['load_pretrain_model']:\n",
        "    config.pretrained_model = pretrain_model_dir\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/nerdk312/Contrastive_learning\" target=\"_blank\">https://app.wandb.ai/nerdk312/Contrastive_learning</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/nerdk312/Contrastive_learning/runs/wpy0wz9a\" target=\"_blank\">https://app.wandb.ai/nerdk312/Contrastive_learning/runs/wpy0wz9a</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtD9K4s3HFw7",
        "colab_type": "text"
      },
      "source": [
        "# Main -  Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JeHblECHRgq",
        "colab_type": "text"
      },
      "source": [
        "Data - Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40FWfGPr3EXj",
        "colab_type": "code",
        "outputId": "d0161775-1879-4f10-b21f-65030e1c35ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "initial_time = time.time()\n",
        "data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity_1'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    data_object.replay_buffer.load(preloaded_train_data_1)\n",
        "else:\n",
        "    data_object.gather_random_trajectories(5000)\n",
        "\n",
        "final_time = time.time() - initial_time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "trajectory number: 0\n",
            "trajectory number: 10\n",
            "trajectory number: 20\n",
            "trajectory number: 30\n",
            "trajectory number: 40\n",
            "trajectory number: 50\n",
            "trajectory number: 60\n",
            "trajectory number: 70\n",
            "trajectory number: 80\n",
            "trajectory number: 90\n",
            "trajectory number: 100\n",
            "trajectory number: 110\n",
            "trajectory number: 120\n",
            "trajectory number: 130\n",
            "trajectory number: 140\n",
            "trajectory number: 150\n",
            "trajectory number: 160\n",
            "trajectory number: 170\n",
            "trajectory number: 180\n",
            "trajectory number: 190\n",
            "trajectory number: 200\n",
            "trajectory number: 210\n",
            "trajectory number: 220\n",
            "trajectory number: 230\n",
            "trajectory number: 240\n",
            "trajectory number: 250\n",
            "trajectory number: 260\n",
            "trajectory number: 270\n",
            "trajectory number: 280\n",
            "trajectory number: 290\n",
            "trajectory number: 300\n",
            "trajectory number: 310\n",
            "trajectory number: 320\n",
            "trajectory number: 330\n",
            "trajectory number: 340\n",
            "trajectory number: 350\n",
            "trajectory number: 360\n",
            "trajectory number: 370\n",
            "trajectory number: 380\n",
            "trajectory number: 390\n",
            "trajectory number: 400\n",
            "trajectory number: 410\n",
            "trajectory number: 420\n",
            "trajectory number: 430\n",
            "trajectory number: 440\n",
            "trajectory number: 450\n",
            "trajectory number: 460\n",
            "trajectory number: 470\n",
            "trajectory number: 480\n",
            "trajectory number: 490\n",
            "trajectory number: 500\n",
            "trajectory number: 510\n",
            "trajectory number: 520\n",
            "trajectory number: 530\n",
            "trajectory number: 540\n",
            "trajectory number: 550\n",
            "trajectory number: 560\n",
            "trajectory number: 570\n",
            "trajectory number: 580\n",
            "trajectory number: 590\n",
            "trajectory number: 600\n",
            "trajectory number: 610\n",
            "trajectory number: 620\n",
            "trajectory number: 630\n",
            "trajectory number: 640\n",
            "trajectory number: 650\n",
            "trajectory number: 660\n",
            "trajectory number: 670\n",
            "trajectory number: 680\n",
            "trajectory number: 690\n",
            "trajectory number: 700\n",
            "trajectory number: 710\n",
            "trajectory number: 720\n",
            "trajectory number: 730\n",
            "trajectory number: 740\n",
            "trajectory number: 750\n",
            "trajectory number: 760\n",
            "trajectory number: 770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LrwrqiJOHld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32a3c23d-80a0-4406-e07d-d93d8202fea2"
      },
      "source": [
        "data_object.replay_buffer.obses.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 100, 100, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43mOgDBl3VCD",
        "colab_type": "code",
        "outputId": "e43ed390-d092-49bb-9dfa-830155550830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data_object_2 = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity_2'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    data_object_2.replay_buffer.load(preloaded_train_data_2)\n",
        "else:\n",
        "    data_object_2.gather_random_trajectories(5000)\n",
        "\n",
        "data_object.replay_buffer.obses = np.concatenate((data_object.replay_buffer.obses, data_object_2.replay_buffer.obses), axis=0)\n",
        "data_object.replay_buffer.actions = np.concatenate((data_object.replay_buffer.actions, data_object_2.replay_buffer.actions), axis=0)\n",
        "data_object.replay_buffer.state_changes = np.concatenate((data_object.replay_buffer.state_changes, data_object_2.replay_buffer.state_changes), axis=0)\n",
        "del data_object_2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "trajectory number: 0\n",
            "trajectory number: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmXktIst3vdm",
        "colab_type": "code",
        "outputId": "cfdf7b56-306d-4398-f9dd-1a9a83b8a8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_object_3 = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity_3'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    data_object_3.replay_buffer.load(preloaded_train_data_2)\n",
        "else:\n",
        "    data_object_3.gather_random_trajectories(5000)\n",
        "\n",
        "data_object.replay_buffer.obses = np.concatenate((data_object.replay_buffer.obses, data_object_3.replay_buffer.obses), axis=0)\n",
        "data_object.replay_buffer.actions = np.concatenate((data_object.replay_buffer.actions, data_object_3.replay_buffer.actions), axis=0)\n",
        "data_object.replay_buffer.state_changes = np.concatenate((data_object.replay_buffer.state_changes, data_object_3.replay_buffer.state_changes), axis=0)\n",
        "\n",
        "del data_object_3"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "trajectory number: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQqnUf9c4qAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict, parse_dict['val_capacity'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    val_data_object.replay_buffer.load(preloaded_val_data)\n",
        "else:\n",
        "    val_data_object.gather_random_trajectories(5000)\n",
        "\n",
        "train_dataloader = DataLoader(data_object.replay_buffer, batch_size = 256, shuffle = True)\n",
        "val_dataloader = DataLoader(val_data_object.replay_buffer, batch_size = 256, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1t5IVqd0rz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent = make_agent(\n",
        "        obs_shape = data_object.obs_shape,\n",
        "        device =data_object.device,\n",
        "        dict_info = parse_dict\n",
        "    )\n",
        "\n",
        "dyn_model_name = 'Dynamics'+ '_' + data_object.ts\n",
        "pretrain_model_name = 'Contrastive' +'_' + data_object.ts\n",
        "\n",
        "early_stopping_dynamics = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=dyn_model_name)\n",
        "early_stopping_contrastive = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=pretrain_model_name)\n",
        "env = gym.make(ENV_NAME)\n",
        "env = custom_wrapper(env, grayscale = parse_dict['grayscale'])\n",
        "obs = env.reset()\n",
        "info_labels = env.labels()\n",
        "state = data_object.state_conversion(info_labels)\n",
        "\n",
        "\n",
        "if parse_dict['pretrain_model']:\n",
        "    for pretrain_step in range(num_pretrain_steps):\n",
        "        if early_stopping_contrastive.early_stop: #  Stops the training if early stopping counter is hit\n",
        "            break\n",
        "        agent.pretrain(train_dataloader,val_dataloader, early_stopping_contrastive)\n",
        "\n",
        "\n",
        "for step in range(parse_dict['num_train_steps']):\n",
        "    if early_stopping_dynamics.early_stop: #  Stops the training if early stopping counter is hit\n",
        "        break    \n",
        "    agent.update(train_dataloader,val_dataloader,early_stopping_dynamics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiM3VOqI5Y9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}