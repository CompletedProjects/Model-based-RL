{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CURL_Pacman_110520.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1UROvHOI-JmTk7LtcSI-pTs9Xw-XN9fnc",
      "authorship_tag": "ABX9TyO5+vbJm0wv+xMlsoTfDc0d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Model-based-RL/blob/master/CURL_Pacman_110520_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57XVXKX0pUf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hdnkq3rcJNF",
        "colab_type": "text"
      },
      "source": [
        "# Used to save Pacman video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp0jzlXIcFfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fss3NXoMcIjw",
        "colab_type": "code",
        "outputId": "d025f322-5ec6-4461-ca46-dfd9fec6739e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1\n",
        "!apt-get install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (46.1.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4jLAGgyjflE",
        "colab_type": "text"
      },
      "source": [
        "# Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rD40Izgp1JQ",
        "colab_type": "code",
        "outputId": "14074829-3f54-40b7-a51e-c0987fab9e88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        }
      },
      "source": [
        "#!pip install git+git://github.com/mila-iqia/atari-representation-learning.git\n",
        "#!pip install git+git://github.com/ankeshanand/pytorch-a2c-ppo-acktr-gail\n",
        "!pip install git+git://github.com/openai/baselines\n",
        "!pip install wandb"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/openai/baselines\n",
            "  Cloning git://github.com/openai/baselines to /tmp/pip-req-build-5ksu29oe\n",
            "  Running command git clone -q git://github.com/openai/baselines /tmp/pip-req-build-5ksu29oe\n",
            "Requirement already satisfied (use --upgrade to upgrade): baselines==0.1.6 from git+git://github.com/openai/baselines in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: gym<0.16.0,>=0.15.4 in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (0.15.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (0.14.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.1.2.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.4)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.16.0)\n",
            "Building wheels for collected packages: baselines\n",
            "  Building wheel for baselines (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for baselines: filename=baselines-0.1.6-cp36-none-any.whl size=220664 sha256=a19503f4726b98183b5903aedae4cd537822f4fe5dd918870df4cd8f5e1be811\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-powxntfx/wheels/42/1c/91/28314e0cd1d2cc57cf8dd18b20c4c9a0f39ae518adc13caf24\n",
            "Successfully built baselines\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.8.35)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied: gql==0.2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.2.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.14.3)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.0)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
            "Requirement already satisfied: graphql-core<2,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (1.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNPbRVOCqA3q",
        "colab_type": "code",
        "outputId": "839c5d26-7d1f-44fe-fad7-3023fcf7f1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!wandb login ##############"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI287_Yjxn3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from __future__ import print_function\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "import wandb\n",
        "\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "from Contrastive_loss_Pacman.custom_wrappers import custom_wrapper\n",
        "from Contrastive_loss_Pacman.encoder import make_encoder\n",
        "from Contrastive_loss_Pacman.EarlyStopping import EarlyStopping_loss\n",
        "from Contrastive_loss_Pacman.GeneralFunctions import General_functions\n",
        "from Contrastive_loss_Pacman.utils import make_dir, random_crop,center_crop_image, soft_update_params, weight_init\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import gym\n",
        "\n",
        "# Needed to create dataloaders\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YeWKrKFXuuY",
        "colab_type": "text"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMRcLI41UQwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayBuffer(Dataset):\n",
        "    \"\"\"Buffer to store environment transitions.\"\"\"\n",
        "    def __init__(self, obs_shape,action_shape, state_shape,capacity, batch_size, device,image_size=84,rand_crop = True,transform=None):\n",
        "        self.capacity = capacity\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "        self.image_size = image_size\n",
        "        self.rand_crop = rand_crop\n",
        "        self.transform = transform\n",
        "\n",
        "        obs_dtype = np.uint8 # Need to consider the sign of this\n",
        "        self.obses = np.empty((capacity, *obs_shape), dtype=obs_dtype)\n",
        "        self.actions = np.empty((capacity,*action_shape),dtype = np.float32)\n",
        "        self.state_changes = np.empty((capacity, *state_shape), dtype = np.float32) \n",
        "\n",
        "        self.idx = 0\n",
        "        self.last_save = 0\n",
        "        self.full = False\n",
        "\n",
        "    def add(self, obs,action,state_change): # Nawid- Add information to replay buffer\n",
        "        \n",
        "        np.copyto(self.obses[self.idx], obs)\n",
        "        np.copyto(self.actions[self.idx], action)\n",
        "        np.copyto(self.state_changes[self.idx], state_change)\n",
        "\n",
        "        self.idx = (self.idx + 1) % self.capacity # This makes the data gets replaced in a recursive manner when the capacity is full\n",
        "        self.full = self.full or self.idx == 0\n",
        "    \n",
        "    def sample_cpc(self): # Nawid - samples images I believe\n",
        "\n",
        "        start = time.time()\n",
        "        idxs = np.random.randint(\n",
        "            0, self.capacity if self.full else self.idx, size=self.batch_size\n",
        "        ) # Used to randomly sample indices\n",
        "\n",
        "        obses = self.obses[idxs] # Nawid - Samples observation\n",
        "        pos = obses.copy() # Nawid -\n",
        "\n",
        "        # Random crop or centre crops the image\n",
        "        if self.rand_crop:\n",
        "            obses_input = random_crop(obses,self.image_size)\n",
        "        else:\n",
        "            obses_input = center_crop_image(obses, self.image_size)  \n",
        "\n",
        "        # Nawid - Crop images randomly\n",
        "        obses = random_crop(obses, self.image_size)\n",
        "        pos = random_crop(pos, self.image_size)\n",
        "\n",
        "        obses_input = torch.tensor(obses_input, device= self.device).float()\n",
        "        obses = torch.as_tensor(obses, device=self.device).float()\n",
        "        pos = torch.as_tensor(pos, device=self.device).float()\n",
        "        actions = torch.as_tensor(self.actions[idxs], device=self.device)\n",
        "        state_changes = torch.as_tensor(self.state_changes[idxs], device=self.device) \n",
        "        \n",
        "        cpc_kwargs = dict(obs_anchor=obses, obs_pos=pos,\n",
        "                          time_anchor=None, time_pos=None) # Nawid  Postitive example is pos whilst anchor is obses\n",
        "\n",
        "        return obses_input, actions, state_changes, cpc_kwargs\n",
        "        \n",
        "    def save(self, save_dir):\n",
        "        path = os.path.join(save_dir, '%d_%d.pt' % (self.last_save, self.capacity))\n",
        "        payload = [\n",
        "            self.obses[0:self.capacity], #  Changed the payload compared to their training as I intend to use a offline training at the moment\n",
        "            self.actions[0:self.capacity],\n",
        "            self.state_changes[0:self.capacity]\n",
        "        ]\n",
        "        torch.save(payload, path)\n",
        "    \n",
        "    def load(self, save_dir): # Nawid - Loads the data into the replay buffer\n",
        "        chunks = os.listdir(save_dir)\n",
        "        chucks = sorted(chunks, key=lambda x: int(x.split('_')[0]))\n",
        "        for chunk in chucks:\n",
        "            start, end = [int(x) for x in chunk.split('.')[0].split('_')]\n",
        "            path = os.path.join(save_dir, chunk)\n",
        "            payload = torch.load(path)\n",
        "            assert self.idx == start\n",
        "            self.obses[start:end] = payload[0]\n",
        "            self.actions[start:end] = payload[1]\n",
        "            self.state_changes[start:end] = payload[2]\n",
        "            self.idx = end\n",
        "\n",
        "    def __getitem__(self, idx): # Nawid - Obtains item from replay buffer\n",
        "        ''' Remove the randomness in the dataloading of each sample as the dataloader itself should be able to find the different values\n",
        "        idx = np.random.randint(\n",
        "            0, self.capacity if self.full else self.idx, size=1\n",
        "        )\n",
        "        idx = idx[0]\n",
        "        '''\n",
        "        obses = np.expand_dims(self.obses[idx],0) # Need to expand dim to allow it to be the shape for cropping, then need to squeeze so its a 4d tensor rather than 5d with an extra dim so it can be used with the dataloader\n",
        "        pos = obses.copy()\n",
        "        #center crop image\n",
        "        if self.rand_crop:\n",
        "            obses_input = random_crop(obses,self.image_size) #center_crop_image(obses,self.image_size) # \n",
        "        else:\n",
        "            obses_input = center_crop_image(obses, self.image_size)\n",
        "\n",
        "        # random crop images\n",
        "        obses = random_crop(obses, self.image_size)\n",
        "        pos = random_crop(pos, self.image_size)\n",
        "\n",
        "        obses = np.squeeze(obses)\n",
        "        pos = np.squeeze(pos)\n",
        "\n",
        "        action = self.actions[idx]\n",
        "        state_change = self.state_changes[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            obses = self.transform(obses)\n",
        "\n",
        "        cpc_kwargs = dict(obs_anchor=obses, obs_pos=pos) # Nawid  Postitive example is pos whilst anchor is obses\n",
        "                          \n",
        "        return obses_input, action, state_change, cpc_kwargs\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.capacity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDaFHhxLacNp",
        "colab_type": "text"
      },
      "source": [
        "# CURL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0azXaHveIzM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CURL(nn.Module): # Nawid - Module for the contrastive loss\n",
        "    \"\"\"\n",
        "    CURL\n",
        "    \"\"\"\n",
        "    def __init__(self, obs_shape, z_dim, encoder_feature_dim, num_layers, num_filters):\n",
        "        super(CURL, self).__init__()\n",
        "\n",
        "        # Need to fix the encoders since I do not plan to use the critics\n",
        "        self.encoder = make_encoder( # Nawid - Encoder of critic which is also used for the contrastive loss\n",
        "            obs_shape, encoder_feature_dim, num_layers,\n",
        "            num_filters, output_logits=True)\n",
        "\n",
        "        self.encoder_target = make_encoder(obs_shape, encoder_feature_dim, num_layers, \n",
        "                                           num_filters, output_logits=True)\n",
        "        \n",
        "        self.encoder_target.load_state_dict(self.encoder.state_dict()) # copies the parameters of the encoder into the target encoder which is changing slowly\n",
        "        self.W = nn.Parameter(torch.rand(z_dim, z_dim)) # Nawid - weight vector for the bilinear product\n",
        "\n",
        "    def encode(self, x, detach=False, ema=False):\n",
        "        \"\"\"\n",
        "        Encoder: z_t = e(x_t)\n",
        "        :param x: x_t, x y coordinates\n",
        "        :return: z_t, value in r2\n",
        "        \"\"\"\n",
        "        if ema:\n",
        "            with torch.no_grad():\n",
        "                z_out = self.encoder_target(x)\n",
        "        else:\n",
        "            z_out = self.encoder(x)\n",
        "\n",
        "        if detach:\n",
        "            z_out = z_out.detach()\n",
        "        return z_out\n",
        "    \n",
        "    def compute_logits(self, z_a, z_pos): # Nawid -  computes logits for contrastive loss\n",
        "        \"\"\"\n",
        "        Uses logits trick for CURL:\n",
        "        - compute (B,B) matrix z_a (W z_pos.T)\n",
        "        - positives are all diagonal elements\n",
        "        - negatives are all other elements\n",
        "        - to compute loss use multiclass cross entropy with identity matrix for labels\n",
        "        \"\"\"\n",
        "        Wz = torch.matmul(self.W, z_pos.T)  # (z_dim,B)\n",
        "        logits = torch.matmul(z_a, Wz)  # (B,B)\n",
        "        logits = logits - torch.max(logits, 1)[0][:, None]\n",
        "        return logits\n",
        "\n",
        "\n",
        "class Dynamics_model(nn.Module):\n",
        "    ''' MLP network'''\n",
        "    def __init__(self, obs_shape,hidden_dim,\n",
        "                 output_dim , encoder_feature_dim, num_layers, num_filters):\n",
        "        super(Dynamics_model,self).__init__()\n",
        "\n",
        "        self.encoder = make_encoder(obs_shape, encoder_feature_dim,num_layers,num_filters,output_logits=True)\n",
        "\n",
        "        self.trunk = nn.Sequential(\n",
        "            nn.Linear(self.encoder.feature_dim + 4 , hidden_dim),nn.BatchNorm1d(num_features=hidden_dim), nn.ReLU(), # Size of the input is related to the encoder output as well as the concatenated one hot vector for the actions\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.BatchNorm1d(num_features=hidden_dim), nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "        self.apply(weight_init)\n",
        "    \n",
        "    def forward(self, obs,aux, detach_encoder = False):\n",
        "        obs = self.encoder(obs, detach = detach_encoder) \n",
        "        obs = torch.cat((obs, aux), 1) # Join vectors along this dimension\n",
        "        prediction = self.trunk(obs)        \n",
        "        return prediction\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc15PakPabSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CurlAgent(object):\n",
        "    ''' CURL representation learning'''\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_shape,\n",
        "        device,\n",
        "        hidden_dim = 256,\n",
        "        output_dim = 2,\n",
        "        encoder_feature_dim = 50,\n",
        "        encoder_lr = 1e-3,\n",
        "        encoder_tau = 0.005,\n",
        "        num_layers=4,\n",
        "        num_filters = 32,\n",
        "        cpc_update_freq=1,\n",
        "        encoder_update_freq = 2,\n",
        "        detach_encoder=False,\n",
        "    ):\n",
        "        self.device = device\n",
        "        self.cpc_update_freq = cpc_update_freq\n",
        "        self.image_size = obs_shape[-2] # Changed this to the numpy dimension\n",
        "        self.detach_encoder = detach_encoder\n",
        "        self.encoder_update_freq = encoder_update_freq\n",
        "        self.encoder_tau = encoder_tau\n",
        "        self.epoch_step = 0\n",
        "        \n",
        "        self.CURL = CURL(obs_shape, encoder_feature_dim,\n",
        "                         encoder_feature_dim, num_layers, num_filters).to(self.device)\n",
        "        \n",
        "        self.Model = Dynamics_model(obs_shape,hidden_dim,output_dim,encoder_feature_dim,num_layers,num_filters).to(self.device)\n",
        "\n",
        "        # tie encoders between and CURL and dynamics predictor - VERY IMPORTANT-  CAN REMOVE IF I WANT SEPARATE NETWORKS\n",
        "        self.Model.encoder.copy_conv_weights_from(self.CURL.encoder)\n",
        "\n",
        "        self.cpc_optimizer = torch.optim.Adam(\n",
        "                self.CURL.parameters(), lr=encoder_lr\n",
        "            )\n",
        "        \n",
        "        self.dynamics_optimizer = torch.optim.Adam(self.Model.parameters(), lr= encoder_lr)\n",
        "\n",
        "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "        self.MSE_loss = nn.MSELoss() # Nawid - Added this loss for the prediction\n",
        "        self.train()\n",
        "\n",
        "        #wandb.watch(self.CURL, log='all') #  Seems that I cannot use the wand.watch for the CURL model or the dynamics model(when the weights are shared between the dynamics and curl model)\n",
        "        #wandb.watch(self.Model, log='all')\n",
        "    \n",
        "    def train(self, training = True):\n",
        "        self.training = training\n",
        "        self.CURL.train(training)\n",
        "        self.Model.train(training)\n",
        "\n",
        "    def update(self, training_replay_buffer,val_dataloader,early_stopper,step):\n",
        "        #torch.cuda.empty_cache() # Releases cache so the GPU has more memory\n",
        "        if early_stopper.early_stop:\n",
        "            print('early stopping')\n",
        "            return\n",
        "\n",
        "        obs, actions_one_hot,predicted_change, cpc_kwargs = training_replay_buffer.sample_cpc()\n",
        "        \n",
        "        if step % self.encoder_update_freq == 0:\n",
        "            soft_update_params(\n",
        "                self.CURL.encoder, self.CURL.encoder_target,\n",
        "                self.encoder_tau\n",
        "            )\n",
        "        \n",
        "        if step % self.cpc_update_freq == 0:\n",
        "            \n",
        "            obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "            self.update_cpc(obs_anchor, obs_pos,cpc_kwargs) # Nawid -  Performs the contrastive loss I believe\n",
        "        \n",
        "        if step % 2 ==0:    \n",
        "            self.update_dynamics(obs, actions_one_hot,predicted_change)\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            self.validation(val_dataloader,early_stopper)\n",
        "\n",
        "    def update_cpc(self, obs_anchor, obs_pos, cpc_kwargs):\n",
        "        z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "        z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "\n",
        "        logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "        labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "        loss = self.cross_entropy_loss(logits, labels)\n",
        "        wandb.log({'Contrastive Training loss':loss.item()})\n",
        "\n",
        "        self.cpc_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        self.cpc_optimizer.step()  # Nawid - Used to update the cpc\n",
        "    \n",
        "    def update_dynamics(self, obs,actions, labels):\n",
        "        prediction = self.Model(obs,actions,detach_encoder=True) # gradient not backpropagated to the encoder\n",
        "        prediction_loss = self.MSE_loss(prediction,labels)\n",
        "        wandb.log({'Dynamics Training loss':prediction_loss.item()}) #  Need to use .item otherwise the loss will still be kept which will reduce the memory on the GPU\n",
        "        \n",
        "        self.dynamics_optimizer.zero_grad()\n",
        "        prediction_loss.backward()\n",
        "        self.dynamics_optimizer.step()\n",
        "\n",
        "    def validation(self, dataloader,early_stopper):\n",
        "        epoch_contrastive_loss = 0\n",
        "        epoch_dynamics_loss = 0 \n",
        "        self.Model.eval()\n",
        "        self.CURL.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (obses, actions, state_change, cpc_kwargs) in enumerate(dataloader):\n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "\n",
        "                obses = obses.float().to(self.device)\n",
        "                obs_anchor = obs_anchor.float().to(self.device)\n",
        "                obs_pos = obs_pos.float().to(self.device)\n",
        "                actions = actions.to(self.device)\n",
        "                state_change = state_change.to(self.device)\n",
        "                \n",
        "                z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "                z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "                logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "                labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "                loss = self.cross_entropy_loss(logits, labels)\n",
        "                epoch_contrastive_loss += loss.item()\n",
        "                \n",
        "                val_prediction = self.Model(obs_anchor,actions,detach_encoder=False) # gradient not backpropagated to the encoder\n",
        "                val_prediction_loss = self.MSE_loss(val_prediction,state_change)\n",
        "                epoch_dynamics_loss += val_prediction_loss.item()\n",
        "            \n",
        "            average_epoch_contrastive_loss = epoch_contrastive_loss/i\n",
        "            average_epoch_dynamics_loss = epoch_dynamics_loss/i            \n",
        "            \n",
        "            self.epoch_step += 1 # increase epoch counter\n",
        "            wandb.log({'Contrastive Validation loss':average_epoch_contrastive_loss,'Dynamics Validation loss':average_epoch_dynamics_loss,'epoch': self.epoch_step})\n",
        "            print('epoch:', self.epoch_step)\n",
        "            print('val prediction:', val_prediction[0:20]) #  batch of the val prediction is the size of the last batch so it will be what is leftover till the set is complete\n",
        "            print('state change:',state_change[0:20])\n",
        "\n",
        "            early_stopper(average_epoch_dynamics_loss,self.Model,self.dynamics_optimizer)\n",
        "\n",
        "        self.train()\n",
        "\n",
        "def make_agent(obs_shape, device, dict_info):\n",
        "    return CurlAgent(\n",
        "        obs_shape = obs_shape,\n",
        "        device = device,\n",
        "        encoder_update_freq =dict_info['encoder_update_freq'],\n",
        "        encoder_feature_dim = dict_info['encoder_feature_dim'],\n",
        "        encoder_lr = dict_info['encoder_lr'],\n",
        "        encoder_tau = dict_info['encoder_tau'],\n",
        "        num_layers = dict_info['num_layers'],\n",
        "        num_filters = dict_info['num_filters']\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taJgI07xT7eo",
        "colab_type": "text"
      },
      "source": [
        "# Data collection and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL0DwKk3XLAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data_collection(General_functions):\n",
        "    def __init__(self, ENV_NAME, n_actions, possible_positions,info_dict,buffer_capacity):\n",
        "        super(Data_collection, self).__init__(ENV_NAME, n_actions, possible_positions)\n",
        "        self.grayscale = info_dict['grayscale']\n",
        "        self.channels = 1 if self.grayscale else 3 \n",
        "        self.obs_shape = (info_dict['image_size'], info_dict['image_size'],self.channels*info_dict['frame_stack']) # Nawid - Stack together images (multiply of 3 present due to 3 channels (RGB))\n",
        "        self.pre_aug_obs_shape = (info_dict['pre_transform_image_size'],info_dict['pre_transform_image_size'],self.channels*info_dict['frame_stack'])\n",
        "        self.action_shape = (n_actions,)   \n",
        "        self.state_shape = (2,)     \n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        self.replay_buffer  = ReplayBuffer(self.pre_aug_obs_shape,self.action_shape,self.state_shape,self.buffer_capacity, info_dict['batch_size'],self.device, info_dict['image_size'],info_dict['random_crop'])\n",
        "        self.ts = time.gmtime()\n",
        "        self.ts = time.strftime('%d-%m_%H:%M')\n",
        "        self.walls_present = info_dict['walls_present']\n",
        "\n",
        "\n",
        "    def random_action_selection(self, state,prev_action = None):\n",
        "        while True:\n",
        "            action = np.random.randint(1,5) \n",
        "            feasible_action = self.next_position(state,action)\n",
        "            if feasible_action:\n",
        "                self.prev_action_counter = True\n",
        "                return action, None\n",
        "            else:\n",
        "                infeasible_action_one_hot = self.one_hot(action)\n",
        "                if self.prev_action_counter and prev_action !=None:\n",
        "                    return prev_action, infeasible_action_one_hot \n",
        "    \n",
        "    def gather_random_trajectories(self,num_traj):\n",
        "        work_dir = '/content/drive/My Drive/MsPacman-data' + '/' + self.ts +'_capacity-' + str(self.buffer_capacity) +'_grayscale-'+ str(self.grayscale) + '_walls_present-'+ str(self.walls_present)\n",
        "        work_dir = make_dir(work_dir)\n",
        "\n",
        "        for n in range(num_traj):            \n",
        "            if n % 10 ==0:\n",
        "                print('trajectory number:',n)\n",
        "                # Initial set up\n",
        "            #self.env.seed(0)\n",
        "\n",
        "            self.env = gym.make(self.ENV_NAME) # Due to error in code, I reinstantiate the env each time\n",
        "            self.env = custom_wrapper(self.env,grayscale = self.grayscale)\n",
        "            obs = self.env.reset()\n",
        "            \n",
        "            self.repeated_end = False\n",
        "            info_labels = self.env.labels() # Nawid - Used to get the current state\n",
        "            state = self.state_conversion(info_labels) # Used to get the initial state\n",
        "            prev_action = None # Initialise prev action has having no action\n",
        "            \n",
        "            while True:\n",
        "                sampled_action, infeasible_action_one_hot = self.random_action_selection(state,prev_action)\n",
        "                sampled_action_one_hot = self.one_hot(sampled_action)\n",
        "                \n",
        "                next_obs, reward, done, next_info = self.env.step(sampled_action)\n",
        "                next_info_labels = next_info['labels']\n",
        "                \n",
        "                next_state = self.state_conversion(next_info_labels)\n",
        "                state_change = next_state -  state\n",
        "                \n",
        "                self.check_state(state,next_state)\n",
        "                self.check_all_agents(info_labels, next_info_labels) # need to use the info labels to predict the state as the info labels have all the informaiton\n",
        "                    \n",
        "                if not self.repeated_end:            \n",
        "                    if infeasible_action_one_hot is not None and self.walls_present:\n",
        "                        fake_next_state = np.zeros_like(state) #  Need to instantiate a new version each time to prevent updating a single variable which will affect all places(eg lists) where the variable is added\n",
        "                        fake_next_state[0:-2] = next_state[0:-2].copy() # the enemy position of the fake next state is the current enemy position\n",
        "                        fake_next_state[-2:] = state[-2:].copy() # The agent position for the fake next state is the state before any action was taken\n",
        "                        fake_state_change = fake_next_state - state\n",
        "                        self.replay_buffer.add(obs,infeasible_action_one_hot, fake_state_change)\n",
        "\n",
        "                    self.replay_buffer.add(obs,sampled_action_one_hot, state_change)\n",
        "                else:\n",
        "                    done = True   \n",
        "                \n",
        "                obs = next_obs # do not need to copy as a new variable of obs is instantiated at each time step.\n",
        "                state = next_state.copy()\n",
        "                info_labels = next_info_labels.copy()\n",
        "                prev_action = sampled_action\n",
        "\n",
        "                if done:\n",
        "                    break    \n",
        "                if self.replay_buffer.full:\n",
        "                    self.replay_buffer.save(work_dir)\n",
        "                    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4SvnJeJUgM",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHK7nCaJT-J",
        "colab_type": "code",
        "outputId": "976c0e60-0cb7-4606-97bb-2760b8e7c4e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ENV_NAME = 'MsPacmanDeterministic-v4'\n",
        "n_actions = 4 #9 - Nawid - Change to 5 actions as the 4 other actions are simply copies of the other actions, therefore 5 actions should lower the amount of data needed.\n",
        "parse_dict= {'pre_transform_image_size':100,\n",
        "             'image_size':84,\n",
        "             'frame_stack':4,\n",
        "             'train_capacity':1000,\n",
        "             'val_capacity':1000,\n",
        "             'num_train_steps':20000,\n",
        "             'batch_size':256,\n",
        "             'random_crop': True,\n",
        "             'encoder_update_freq':2,\n",
        "             'encoder_feature_dim':50,\n",
        "             'encoder_lr':1e-3,\n",
        "             'encoder_tau':0.05,\n",
        "             'num_layers':4,\n",
        "             'num_filters':32,\n",
        "             'load_trajectories':True,\n",
        "             'grayscale': True,\n",
        "             'pretrain_model': False,\n",
        "             'walls_present': False\n",
        "            }\n",
        "\n",
        "wandb.init(entity=\"nerdk312\", project=\"Contrastive_learning\",config = parse_dict)\n",
        "\n",
        "possible_positions = np.load('/content/drive/My Drive/MsPacman-data/possible_pacman_positions.npy',allow_pickle=True)\n",
        "preloaded_train_data = '/content/drive/My Drive/MsPacman-data/11-05_16:56-grayscale-True-walls_present-False' #'/content/drive/My Drive/MsPacman-data/Data_obstacles_present/80000_10-05_13:35/buffer'\n",
        "preloaded_val_data =  '/content/drive/My Drive/MsPacman-data/11-05_17:02_capacity-1000_grayscale-True_walls_present-False_capacity-' #'/content/drive/My Drive/MsPacman-data/Data_obstacles_present/10000_09-05_17:05/buffer' \n",
        "\n",
        "config = wandb.config\n",
        "if parse_dict['load_trajectories']:\n",
        "    config.loaded_train_trajectories = preloaded_train_data\n",
        "    config.loaded_val_trajectories = preloaded_val_data\n",
        "\n",
        "if parse_dict['pretrain_model']:\n",
        "    config.pretrained_model = pretrain_model_dir"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/nerdk312/Contrastive_learning\" target=\"_blank\">https://app.wandb.ai/nerdk312/Contrastive_learning</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/nerdk312/Contrastive_learning/runs/3b4vsf7y\" target=\"_blank\">https://app.wandb.ai/nerdk312/Contrastive_learning/runs/3b4vsf7y</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtD9K4s3HFw7",
        "colab_type": "text"
      },
      "source": [
        "# Main -  Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JeHblECHRgq",
        "colab_type": "text"
      },
      "source": [
        "Data - Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsds_oc41VHC",
        "colab_type": "code",
        "outputId": "19125ad6-ea42-445e-ebf4-f1104e203203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity'])\n",
        "val_data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict, parse_dict['val_capacity'])\n",
        "\n",
        "if parse_dict['load_trajectories']:\n",
        "    data_object.replay_buffer.load(preloaded_train_data)\n",
        "    val_data_object.replay_buffer.load(preloaded_val_data)\n",
        "else:\n",
        "    data_object.gather_random_trajectories(5000)\n",
        "    val_data_object.gather_random_trajectories(5000)\n",
        "\n",
        "val_dataloader = DataLoader(val_data_object.replay_buffer, batch_size = 256, shuffle = True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o_EJEBjJ_NX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent = make_agent(\n",
        "        obs_shape = data_object.obs_shape,\n",
        "        device =data_object.device,\n",
        "        dict_info = parse_dict\n",
        "    )\n",
        "\n",
        "dyn_model_name = 'Dynamics'+ '_' + data_object.ts\n",
        "early_stopping_dynamics = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=dyn_model_name)\n",
        "\n",
        "env = gym.make(ENV_NAME)\n",
        "env = custom_wrapper(env, grayscale=True)\n",
        "obs = env.reset()\n",
        "info_labels = env.labels()\n",
        "state = data_object.state_conversion(info_labels)\n",
        "\n",
        "for step in range(parse_dict['num_train_steps']):\n",
        "    if early_stopping_dynamics.early_stop: #  Stops the training if early stopping counter is hit\n",
        "        break\n",
        "\n",
        "    if step >= 0:\n",
        "        agent.update(data_object.replay_buffer,val_dataloader,early_stopping_dynamics,step)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}