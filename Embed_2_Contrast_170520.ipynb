{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embed_2_Contrast_V2_170520.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1bwPf5H18zVf6ueazYZ2bKQqpQVc9XhNy",
      "authorship_tag": "ABX9TyNut4Ut7QL0pzDAOIj3kN7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Model-based-RL/blob/master/Embed_2_Contrast_170520.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcuwm4m-JRFg",
        "colab_type": "code",
        "outputId": "7ab18578-36bb-4228-8fc3-dd2d17d6955a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install git+git://github.com/openai/baselines\n",
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/openai/baselines\n",
            "  Cloning git://github.com/openai/baselines to /tmp/pip-req-build-fr8a_r4y\n",
            "  Running command git clone -q git://github.com/openai/baselines /tmp/pip-req-build-fr8a_r4y\n",
            "Collecting gym<0.16.0,>=0.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/01/8771e8f914a627022296dab694092a11a7d417b6c8364f0a44a8debca734/gym-0.15.7.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (0.14.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.16.0)\n",
            "Building wheels for collected packages: baselines, gym\n",
            "  Building wheel for baselines (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for baselines: filename=baselines-0.1.6-cp36-none-any.whl size=220664 sha256=f0aa208484c6e70a3d304159b1e426c220fc5ec398814453bc793e39ff8e4e73\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-is7fdxb7/wheels/42/1c/91/28314e0cd1d2cc57cf8dd18b20c4c9a0f39ae518adc13caf24\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.7-cp36-none-any.whl size=1648840 sha256=097ff2f5e2369da0b6b2fd80cb184b91bf00b26371f6180cd14d0a13fa05ba64\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/60/6a/f9c27ae133abaf5a5687ed2fa8ed19627d7fac5d843a27572b\n",
            "Successfully built baselines gym\n",
            "\u001b[31mERROR: gym 0.15.7 has requirement cloudpickle~=1.2.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gym, baselines\n",
            "  Found existing installation: gym 0.17.1\n",
            "    Uninstalling gym-0.17.1:\n",
            "      Successfully uninstalled gym-0.17.1\n",
            "Successfully installed baselines-0.1.6 gym-0.15.7\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/c7/8bf2c62c3f133f45e135a8a116e4e0f162043248e3db54de30996eaf1a8a/wandb-0.8.36-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 14.4MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.8MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/95/9a20eebcedab2c1c63fad59fe19a0469edfc2a25b8576497e8084629c2ff/sentry_sdk-0.14.4-py2.py3-none-any.whl (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 39.3MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.8MB/s \n",
            "\u001b[?25hCollecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[?25hCollecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, subprocess32, gql, pathtools, graphql-core\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=8d3a92dc7f03ce66cec44b5196b4f5c96ea530aff942f68b6fc1fae7ba18c3d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=aed1becea4e0256965970d3695455f63ca34c277150a737d1df675c6de76a8a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=4f352da24699647bf9b12c7641fed590ce070a078a28521d2f765668f98c116d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=6cc519cfcbacfc0aa4771d67fc039f9126cf0c74a38b2e25c719fe4e2a72598e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=64a354732ddf54a9facac918fed2287febc3a5805fdf708e3ba9512e52f078d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "Successfully built watchdog subprocess32 gql pathtools graphql-core\n",
            "Installing collected packages: docker-pycreds, smmap, gitdb, GitPython, shortuuid, pathtools, watchdog, sentry-sdk, configparser, subprocess32, graphql-core, gql, wandb\n",
            "Successfully installed GitPython-3.1.2 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.14.4 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.8.36 watchdog-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYybYZw1NR8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from __future__ import print_function\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "import wandb\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gym\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from Embed_2_Contrast.custom_wrappers import custom_wrapper\n",
        "from Embed_2_Contrast.encoder import make_encoder\n",
        "from Embed_2_Contrast.EarlyStopping import EarlyStopping_loss\n",
        "from Embed_2_Contrast.GeneralFunctions import General_functions\n",
        "from Embed_2_Contrast.utils import make_dir, random_crop,center_crop_image, soft_update_params, weight_init, random_color_jitter\n",
        "from torch.autograd import Variable\n",
        "from Embed_2_Contrast.DataCollection import Data_collection\n",
        "from Embed_2_Contrast.models import CURL\n",
        "from Embed_2_Contrast.replay_buffer import ReplayBuffer\n",
        "\n",
        "# Needed to create dataloaders\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9nFHczqzvGA",
        "colab_type": "code",
        "outputId": "ef0af933-c679-43df-d088-a1c436f2cac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!wandb login #########"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVMoiXNVY0RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CurlAgent(object):\n",
        "    ''' CURL representation learning'''\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_shape,\n",
        "        device,\n",
        "        frames,\n",
        "        encoder_feature_dim = 50, # This is the size of the embedding used for the \n",
        "        encoder_lr = 1e-4,\n",
        "        encoder_tau = 0.001,\n",
        "        num_layers=4,\n",
        "        num_filters = 32,\n",
        "        cpc_update_freq=1,\n",
        "        encoder_update_freq = 1,\n",
        "        random_jitter = True,\n",
        "        detach_encoder = True\n",
        "    ):\n",
        "        self.device = device\n",
        "        self.cpc_update_freq = cpc_update_freq\n",
        "        self.image_size = obs_shape[-2] # Changed this to the numpy dimension\n",
        "        self.frames = frames\n",
        "\n",
        "        self.encoder_tau = encoder_tau\n",
        "        self.epoch_step = 0\n",
        "        self.encoder_update_freq = encoder_update_freq\n",
        "        self.random_jitter = random_jitter\n",
        "        \n",
        "        self.CURL = CURL(obs_shape, encoder_feature_dim,\n",
        "                         encoder_feature_dim, num_layers, num_filters).to(self.device)\n",
        "        \n",
        "        if self.detach_encoder: # If the encoder for the dynamics network is not being updated , then we only want to use the contrastive loss to update the network\n",
        "            self.Model.encoder.copy_conv_weights_from(self.CURL.encoder) \n",
        "\n",
        "        self.cpc_optimizer = torch.optim.Adam(\n",
        "                self.CURL.parameters(), lr=encoder_lr\n",
        "            )\n",
        "        \n",
        "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "        self.train()\n",
        "    \n",
        "    def train(self, training = True):\n",
        "        self.training = training\n",
        "        self.CURL.train(training)\n",
        "\n",
        "    def update(self, train_dataloader,val_dataloader,early_stopper):\n",
        "        #torch.cuda.empty_cache() # Releases cache so the GPU has more memory\n",
        "        if early_stopper.early_stop:\n",
        "            print('early stopping')\n",
        "            return\n",
        "\n",
        "        for step, (obs, actions, next_obs, cpc_kwargs) in enumerate(train_dataloader):\n",
        "\n",
        "            if step % self.encoder_update_freq == 0:\n",
        "                soft_update_params(\n",
        "                    self.CURL.encoder, self.CURL.encoder_target,\n",
        "                    self.encoder_tau\n",
        "                )\n",
        "            if step % self.cpc_update_freq == 0:            \n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                self.update_cpc(obs_anchor, obs_pos) # Nawid -  Performs the contrastive loss I believe\n",
        "        \n",
        "        self.validation(val_dataloader,early_stopper)\n",
        "    \n",
        "\n",
        "    def update_cpc(self, obs_anchor, obs_pos):\n",
        "        obs_anchor, obs_pos = obs_anchor.to(self.device), obs_pos.to(self.device)\n",
        "        if self.random_jitter:\n",
        "            obs_anchor, obs_pos = random_color_jitter(obs_anchor,batch_size = obs_anchor.shape[0],frames = self.frames), random_color_jitter(obs_pos,batch_size = obs_pos.shape[0],frames= self.frames)\n",
        "\n",
        "        z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "        z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "\n",
        "        logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "        labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "        loss = self.cross_entropy_loss(logits, labels)\n",
        "        wandb.log({'Contrastive Training loss':loss.item()})\n",
        "\n",
        "        self.cpc_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        self.cpc_optimizer.step()  # Nawid - Used to update the cpc\n",
        "    \n",
        "    def validation(self, dataloader,early_stopper):\n",
        "        epoch_contrastive_loss = 0\n",
        "        self.CURL.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (obses, actions, next_obses, cpc_kwargs) in enumerate(dataloader):\n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                obses, obs_anchor,obs_pos = obses.to(self.device), obs_anchor.to(self.device), obs_pos.to(self.device)\n",
        "                if self.random_jitter:\n",
        "                    obs_anchor, obs_pos =  random_color_jitter(obs_anchor,batch_size = obs_anchor.shape[0],frames = self.frames), random_color_jitter(obs_pos,batch_size = obs_pos.shape[0],frames= self.frames)\n",
        "\n",
        "                ''' Code to check the appearance of the image\n",
        "                image = obs_pos[0]\n",
        "                image = image.permute(1, 2, 0)\n",
        "                plt.imshow(image)\n",
        "                plt.figure()\n",
        "                plt.show()\n",
        "                return \n",
        "                ''' \n",
        "                actions, next_obses = actions.to(self.device), next_obses.to(self.device)\n",
        "                z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "                z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "                logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "                labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "                loss = self.cross_entropy_loss(logits, labels)\n",
        "                epoch_contrastive_loss += loss.item()\n",
        "                \n",
        "            average_epoch_contrastive_loss = epoch_contrastive_loss/(i+1)           \n",
        "            self.epoch_step += 1 # increase epoch counter\n",
        "            wandb.log({'Contrastive Validation loss':average_epoch_contrastive_loss,'epoch': self.epoch_step})\n",
        "\n",
        "            print('epoch:', self.epoch_step)\n",
        "            early_stopper(average_epoch_contrastive_loss,self.CURL,self.cpc_optimizer)\n",
        "            \n",
        "        self.train()\n",
        "    \n",
        "def make_agent(obs_shape, device, dict_info):\n",
        "    return CurlAgent(\n",
        "        obs_shape = obs_shape,\n",
        "        device = device,\n",
        "        frames = dict_info['frames'],\n",
        "        detach_encoder =dict_info['detach_encoder'],\n",
        "        random_jitter = dict_info['random_jitter'],\n",
        "        encoder_update_freq =dict_info['encoder_update_freq'],\n",
        "        encoder_feature_dim = dict_info['encoder_feature_dim'], #  size of the embedding from the projection head\n",
        "        encoder_lr = dict_info['encoder_lr'],\n",
        "        encoder_tau = dict_info['encoder_tau'],\n",
        "        num_layers = dict_info['num_layers'],\n",
        "        num_filters = dict_info['num_filters'], # num of conv filters\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb3hT6ju3ZuT",
        "colab_type": "code",
        "outputId": "7729c31c-978b-4d0f-96b4-2a1312d284f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "ENV_NAME = 'MsPacmanDeterministic-v4'\n",
        "n_actions = 4 #9 - Nawid - Change to 5 actions as the 4 other actions are simply copies of the other actions, therefore 5 actions should lower the amount of data needed.\n",
        "'''\n",
        "data_transform =  transforms.Compose([\n",
        "        transforms.ColorJitter(0.8 * 1, 0.8 * 1, 0.8 * 1, 0.2 * 1),\n",
        "        transforms.ToTensor()])\n",
        "'''\n",
        "data_transform = transforms.Compose([\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "no_agents = 5\n",
        "state_space = no_agents*2 \n",
        "\n",
        "parse_dict= {'pre_transform_image_size':100,\n",
        "             'image_size':84,\n",
        "             'frame_stack':True,\n",
        "             'frames': 4,\n",
        "             'state_space':state_space,\n",
        "             'train_capacity':100000,\n",
        "             'val_capacity':20000,\n",
        "             'num_train_epochs':20,\n",
        "             'batch_size':512,\n",
        "             'random_crop': True,\n",
        "             'encoder_update_freq':1,\n",
        "             'encoder_feature_dim':50,\n",
        "             'encoder_lr':1e-3,\n",
        "             'encoder_tau':0.05, # value used for atari experiments in curl\n",
        "             'num_layers':4,\n",
        "             'num_filters':32,\n",
        "             'grayscale': False,\n",
        "             'load_pretrain_model': False,\n",
        "             'walls_present':True,\n",
        "             'pretrain_model':False,\n",
        "             'save_data':False,\n",
        "             'num_pretrain_epochs':25,\n",
        "             'transform': data_transform,\n",
        "             'random_jitter':False,\n",
        "             'detach_encoder:'True\n",
        "            }\n",
        "\n",
        "#custom_name = 'rand_crop-' +str(parse_dict['random_crop'])  + '_gray-' + str(parse_dict['grayscale']) + '_walls-' +str(parse_dict['walls_present'])  + '_pretrain-' + str(parse_dict['pretrain_model'])\n",
        "custom_name = 'Contrastive_hp_testing_random_jitter-'+str(parse_dict['random_jitter']) + '_encoder_tau-' +str(parse_dict['encoder_tau']) \n",
        "wandb.init(entity=\"nerdk312\",name=custom_name, project=\"Embed2Contrast\",config = parse_dict)\n",
        "\n",
        "possible_positions = np.load('/content/drive/My Drive/MsPacman-data/possible_pacman_positions.npy',allow_pickle=True)\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "if parse_dict['load_pretrain_model']:\n",
        "    config.pretrained_model = pretrain_model_dir\n",
        "\n",
        "# Data collection\n",
        "data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity'])\n",
        "val_data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict, parse_dict['val_capacity'])\n",
        "\n",
        "data_object.gather_random_trajectories(5000)\n",
        "val_data_object.gather_random_trajectories(5000)\n",
        "\n",
        "data_object.replay_buffer.crop_control(parse_dict['random_crop'])\n",
        "val_data_object.replay_buffer.crop_control(parse_dict['random_crop'])\n",
        "\n",
        "train_dataloader = DataLoader(data_object.replay_buffer, batch_size = parse_dict['batch_size'], shuffle = True)\n",
        "val_dataloader = DataLoader(val_data_object.replay_buffer, batch_size = parse_dict['batch_size'], shuffle = True)\n",
        "\n",
        "\n",
        "\n",
        "test_info = [0.001,0.005,0.01,0.05,0.1,0.5,1]\n",
        "#tests = len(test_info) + 1\n",
        "tests = 1 \n",
        "\n",
        "for i in range(tests):  \n",
        "    print(i)  \n",
        "    if i >0:\n",
        "        #parse_dict['encoder_tau'] = np.random.uniform(1e-4,1e-2)\n",
        "        #parse_dict['encoder_lr'] = np.random.uniform(1e-3,1e-2)\n",
        "        parse_dict['random_jitter'] = True \n",
        "        parse_dict['encoder_tau'] = test_info[i-1]\n",
        "        custom_name = 'Contrastive_hp_testing_random_jitter-'+str(parse_dict['random_jitter']) + '_encoder_tau-' +str(parse_dict['encoder_tau']) \n",
        "        wandb.init(entity=\"nerdk312\",name=custom_name, project=\"Contrastive_learning\",config = parse_dict)\n",
        "\n",
        "    agent = make_agent(\n",
        "    obs_shape = data_object.obs_shape,\n",
        "    device =data_object.device,\n",
        "    dict_info = parse_dict\n",
        "    )\n",
        "\n",
        "    pretrain_model_name = 'Contrastive' +'_' + data_object.ts\n",
        "    early_stopping_contrastive = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=pretrain_model_name)\n",
        "\n",
        "    for step in range(parse_dict['num_train_epochs']):\n",
        "        if early_stopping_contrastive.early_stop: #  Stops the training if early stopping counter is hit\n",
        "            break    \n",
        "        agent.update(train_dataloader,val_dataloader,early_stopping_contrastive)\n",
        "\n",
        "    wandb.join()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/nerdk312/Embed2Contrast\" target=\"_blank\">https://app.wandb.ai/nerdk312/Embed2Contrast</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/nerdk312/Embed2Contrast/runs/365sw1do\" target=\"_blank\">https://app.wandb.ai/nerdk312/Embed2Contrast/runs/365sw1do</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "cuda\n",
            "trajectory number: 0\n",
            "trajectory number: 10\n",
            "trajectory number: 20\n",
            "trajectory number: 30\n",
            "trajectory number: 40\n",
            "trajectory number: 50\n",
            "trajectory number: 60\n",
            "trajectory number: 70\n",
            "trajectory number: 80\n",
            "trajectory number: 90\n",
            "trajectory number: 100\n",
            "trajectory number: 110\n",
            "trajectory number: 120\n",
            "trajectory number: 130\n",
            "trajectory number: 140\n",
            "trajectory number: 150\n",
            "trajectory number: 160\n",
            "trajectory number: 170\n",
            "trajectory number: 180\n",
            "trajectory number: 190\n",
            "trajectory number: 200\n",
            "trajectory number: 210\n",
            "trajectory number: 220\n",
            "trajectory number: 230\n",
            "trajectory number: 240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7o35e32efx-",
        "colab_type": "code",
        "outputId": "7d8bde46-9e61-4cae-ca79-f5003e402b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_info = [0.001,0.005,0.01,0.5,0.1,0.5,1]\n",
        "test_info[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrhTb1vn5ISO",
        "colab_type": "code",
        "outputId": "59c7ff1c-029c-4430-9de4-8835a966543c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "pretrain_model_name = 'Contrastive' +'_' + data_object.ts\n",
        "early_stopping_contrastive = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=pretrain_model_name)\n",
        "\n",
        "for step in range(parse_dict['num_train_epochs']):\n",
        "    if early_stopping_contrastive.early_stop: #  Stops the training if early stopping counter is hit\n",
        "        break    \n",
        "    agent.update(train_dataloader,val_dataloader,early_stopping_contrastive)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "epoch: 2\n",
            "epoch: 3\n",
            "epoch: 4\n",
            "epoch: 5\n",
            "epoch: 6\n",
            "epoch: 7\n",
            "epoch: 8\n",
            "epoch: 9\n",
            "epoch: 10\n",
            "epoch: 11\n",
            "epoch: 12\n",
            "epoch: 13\n",
            "epoch: 14\n",
            "epoch: 15\n",
            "epoch: 16\n",
            "epoch: 17\n",
            "epoch: 18\n",
            "epoch: 19\n",
            "epoch: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcQ8vLVSYXoD",
        "colab_type": "text"
      },
      "source": [
        "# OLD CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSklZlEuJqXs",
        "colab_type": "code",
        "outputId": "42e7b6f8-948d-4db8-9257-ace527a2da82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "data_object.replay_buffer.transform"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ColorJitter(brightness=[0.19999999999999996, 1.8], contrast=[0.19999999999999996, 1.8], saturation=[0.19999999999999996, 1.8], hue=[-0.2, 0.2])\n",
              "    ToTensor()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__vOWcaHNo9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transform =  transforms.Compose([\n",
        "        transforms.ColorJitter(0.8 * 1, 0.8 * 1, 0.8 * 1, 0.2 * 1),\n",
        "        transforms.ToTensor()])\n",
        "ENV_NAME = 'MsPacmanDeterministic-v4'\n",
        "env = gym.make(ENV_NAME)\n",
        "env = custom_wrapper(env,ATARI_labels=False)\n",
        "obs =  env.reset()\n",
        "values = []\n",
        "while True:\n",
        "    next_obs, reward, done, _ = env.step(1)\n",
        "    \n",
        "    values.append([obs,next_obs])\n",
        "\n",
        "    obs = next_obs\n",
        "    next_obs = 5\n",
        "    if done:\n",
        "        break\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}