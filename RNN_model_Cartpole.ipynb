{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_model_Cartpole.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CuOH1LbAR9nJ",
        "q2L4f98xRx2G",
        "XdooY4UJFT2-",
        "etWChYG5cE4Y",
        "U9cgDpLdTIoY"
      ],
      "authorship_tag": "ABX9TyMsXGUVaIN/tFe0huPEKyfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Model-based-RL/blob/master/RNN_model_Cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTOpbFBBlADd",
        "colab_type": "code",
        "outputId": "cb3730b3-e07c-4521-a84b-8b6530fda5ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import gym\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "torch.manual_seed(1)\n",
        "# Helpful links\n",
        "# https://github.com/omerbsezer/Fast-Pytorch\n",
        "# https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fccdd89f230>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU0t1FFg5V_N",
        "colab_type": "code",
        "outputId": "dcd6d825-9057-4a2e-a13d-b752590260ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "class General_functions():\n",
        "    def __init__(self, ENV_NAME,n_actions):\n",
        "        self.ENV_NAME = ENV_NAME\n",
        "        self.env = gym.make(self.ENV_NAME)\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.n_actions = n_actions\n",
        "\n",
        "    def one_hot(self,i):\n",
        "        a = np.zeros(self.n_actions, 'uint8')\n",
        "        a[i-1] = 1\n",
        "        return a\n",
        "\n",
        "class Data_collection(General_functions):\n",
        "    def __init__(self,ENV_NAME,n_actions):\n",
        "        super(Data_collection,self).__init__(ENV_NAME,n_actions)\n",
        "        self.dataset_random = [] # Where the data is saved each time\n",
        "        \n",
        "\n",
        "    def collate_data(self,random_dataset, rl_dataset):\n",
        "        rand_data = np.array(random_dataset)\n",
        "        num_rand_examples = len(rand_data)\n",
        "        D_train = rand_data[:int(-num_rand_examples*1/5)] \n",
        "        D_valid = rand_data[int(-num_rand_examples*1/5):]\n",
        "        print(\"number random examples:\",num_rand_examples, 'len(D_train_rand)', len(D_train),'len(D_valid_rand)', len(D_valid))\n",
        "        if len(rl_dataset) > 0:\n",
        "            # Adds the rl dataset to the random dataset if there is any present\n",
        "            rl_data = np.array(rl_dataset)\n",
        "            num_rl_examples = len(rl_data)\n",
        "            D_rl_train = rl_data[:int(-num_rl_examples*1/5)] \n",
        "            D_rl_valid = rl_data[int(-num_rl_examples*1/5):]\n",
        "                        \n",
        "            D_train = np.concatenate([D_train, D_rl_train], axis = 0)\n",
        "            D_valid = np.concatenate([D_valid, D_rl_valid], axis = 0)\n",
        "            print(\"number rl examples:\",num_rl_examples, 'len(D_rl_train)', len(D_rl_train),'len(D_valid_rand)', len(D_rl_valid))\n",
        "            \n",
        "        #print(\"len(D_train):\", len(D_train), 'len(D_valid)', len(D_valid))\n",
        "\n",
        "        # Shuffle the dataset\n",
        "        '''        \n",
        "        sff = np.arange(len(D_train))\n",
        "        np.random.shuffle(sff)\n",
        "        D_train = D_train[sff]\n",
        "        '''\n",
        "        #print('D_train shape',D_train.shape)\n",
        "\n",
        "        # Create the input and output for the train\n",
        "        X_train_obs = np.array([obs for obs,_,_,_,_ in D_train]) # Takes obs and action\n",
        "        X_train_obs = X_train_obs.astype(np.float32)\n",
        "        #X_train_obs = X_train_obs.astype(np.int16) # Need to change it to a int16 so it is signed ( so negative values can be calculated)\n",
        "        X_train_act = np.array([act for _,_,_,_,act in D_train])\n",
        "        \n",
        "        # Env output\n",
        "        y_env_train = np.array([no for _,no,_,_,_ in D_train])\n",
        "        y_env_train = y_env_train.astype(np.float32)\n",
        "        #y_env_train = y_env_train.astype(np.int16) # Need to change it to a int16 so it is signed ( so negative values can be calculated)\n",
        "        y_env_train = y_env_train - X_train_obs \n",
        "        \n",
        "        # Next state output\n",
        "        X_val_obs = np.array([obs for obs,_,_,_,_ in D_valid]) # Takes obs and action\n",
        "        X_val_obs = X_val_obs.astype(np.float32)\n",
        "        #X_val_obs = X_val_obs.astype(np.int16) # Need to change it to a int16 so it is signed ( so negative values can be calculated)        \n",
        "        X_val_act = np.array([act for _,_,_,_,act in D_valid])\n",
        "\n",
        "        y_env_val = np.array([no for _,no,_,_,_ in D_valid])\n",
        "        y_env_val = y_env_val.astype(np.float32)\n",
        "        #y_env_val = y_env_val.astype(np.int16)\n",
        "        y_env_val = y_env_val - X_val_obs \n",
        "\n",
        "        env_train_data, env_val_data = (X_train_obs, X_train_act, y_env_train), (X_val_obs, X_val_act, y_env_val)\n",
        "        return env_train_data, env_val_data\n",
        "    \n",
        "    def normalise(self,train_data, val_data, scaler = None): # Nawid - Used to normalise each dimension individually\n",
        "        if scaler is None:\n",
        "            scaler = StandardScaler()\n",
        "            train_data = scaler.fit_transform(train_data)\n",
        "        else: \n",
        "            train_data = scaler.transform(train_data)\n",
        "        \n",
        "        val_data = scaler.transform(val_data)\n",
        "        return train_data, val_data, scaler\n",
        "    \n",
        "    def normalise_dataset(self,env_train_data, env_val_data, X_env_obs_scaler = None,y_env_scaler=None):\n",
        "        (X_env_train_obs, X_env_train_act, y_env_train), (X_env_val_obs, X_env_val_act, y_env_val) = env_train_data, env_val_data\n",
        "        \n",
        "        X_env_train_obs,X_env_val_obs, X_env_obs_scaler =  self.normalise(X_env_train_obs, X_env_val_obs, X_env_obs_scaler)\n",
        "        y_env_train, y_env_val, y_env_scaler = self.normalise(y_env_train, y_env_val, y_env_scaler)\n",
        "    \n",
        "    \n",
        "        X_env_train = np.concatenate((X_env_train_obs,X_env_train_act),axis=1)\n",
        "        X_env_val = np.concatenate((X_env_val_obs,X_env_val_act),axis=1)\n",
        "        env_train_data, env_val_data = (X_env_train, y_env_train),(X_env_val, y_env_val)    \n",
        "\n",
        "        return env_train_data, env_val_data,X_env_obs_scaler, y_env_scaler\n",
        "\n",
        "    \n",
        "    def gather_random_trajectories(self,num_traj):\n",
        "        for n in range(num_traj):\n",
        "            if n % 10 ==0:\n",
        "                print('trajectory number:',n)\n",
        "                # Initial set up\n",
        "            #self.env.seed(0)\n",
        "            self.env = gym.make(self.ENV_NAME)\n",
        "            obs = self.env.reset()\n",
        "            \n",
        "            while True:\n",
        "                sampled_action = np.random.randint(0,2)\n",
        "                 \n",
        "                sampled_action_one_hot = self.one_hot(sampled_action)\n",
        "                next_obs, reward, done, next_info = self.env.step(sampled_action)\n",
        "                    \n",
        "                self.dataset_random.append([obs, next_obs, reward, done,sampled_action_one_hot])\n",
        "\n",
        "                obs =  next_obs\n",
        "                if done:\n",
        "                    break \n",
        "        return self.dataset_random\n",
        "    \n",
        "ENV_NAME = 'CartPole-v0'\n",
        "n_actions = 2 \n",
        "data_collector = Data_collection(ENV_NAME, n_actions)   \n",
        "rand_dataset = data_collector.gather_random_trajectories(10)\n",
        "rl_dataset = []\n",
        "env_train,env_val = data_collector.collate_data(rand_dataset, rl_dataset)\n",
        "full_env_train,full_env_val,X_env_obs_scaler, y_env_scaler = data_collector.normalise_dataset(env_train,env_val)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trajectory number: 0\n",
            "number random examples: 175 len(D_train_rand) 140 len(D_valid_rand) 35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8_gFotqUd0d",
        "colab_type": "code",
        "outputId": "1324e0d7-ea4d-4d97-a91b-cb21073fc1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train, y_train = full_env_train\n",
        "print(x_train.dtype)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_A5j9mwtdwu",
        "colab_type": "text"
      },
      "source": [
        "# Sequence prediction with batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LDmp87KklET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class state_predictor(nn.Module):\n",
        "  def __init__(self,input_size, hidden_state_size,output_size):\n",
        "    super(state_predictor, self).__init__()    \n",
        "    self.lstm=nn.LSTM(input_size,hidden_state_size)\n",
        "    self.linear=nn.Linear(hidden_state_size, output_size)\n",
        "\n",
        "  def forward(self,x,h):\n",
        "    # h: hidden_state, c=output\n",
        "    # x= x.view(batch_size,timesteps,embed_size)\n",
        "    #print(h[0].shape)\n",
        "    #print('x shape:',x.shape)\n",
        "    lstm_out,(h,c)=self.lstm(x,h)\n",
        "    #print(out.size())\n",
        "    #(batch_size*timesteps, hidden_size)\n",
        "    #out.size(0):batch_size; out.size(1):timesteps, out.size(2): hidden_size\n",
        "    fc_input=lstm_out.reshape(lstm_out.size(0)*lstm_out.size(1),lstm_out.size(2)) # flattens the matrix\n",
        "    #print('post reshape',out.size())\n",
        "    # decode hidden states of all time steps\n",
        "    out= self.linear(fc_input)\n",
        "    out = out.reshape(lstm_out.size(0), lstm_out.size(1), out.size(1)) # dimensions timesteps, batch, output size\n",
        "    #print(out.size())\n",
        "    # Should reshape the network to make it have timesteps, batchsize and state_size\n",
        "    return out, (h,c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vU9EmWxQ_sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_input = 6\n",
        "state_output = 4\n",
        "hidden_size = 1024\n",
        "learning_rate = 0.002\n",
        "num_layers = 1\n",
        "num_directions = 1\n",
        "\n",
        "model = state_predictor(state_input,hidden_size,state_output)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "batch_size = 5\n",
        "timesteps = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3KsIQbsvTfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "dc483fca-6be0-4d18-df5f-80542fcbe7ab"
      },
      "source": [
        "for it in range(10):\n",
        "    for i in range(0,len(x_train), timesteps*batch_size):\n",
        "        if len(x_train) > i + (timesteps*batch_size):\n",
        "            x = x_train[i:i+(timesteps*batch_size),:]\n",
        "            y = y_train[i:i+(timesteps*batch_size),:]\n",
        "\n",
        "            inputs = torch.tensor(x)\n",
        "            inputs = inputs.view(timesteps,batch_size,-1)\n",
        "\n",
        "            targets = torch.tensor(y)\n",
        "            targets = targets.view(timesteps,batch_size,-1)\n",
        "\n",
        "            states = (torch.zeros(num_layers*num_directions,batch_size,hidden_size),\n",
        "                    torch.zeros(num_layers*num_directions,batch_size,hidden_size)) # Dim ((num_layers * num_direction,batch_size, hidden_size)\n",
        "\n",
        "            outputs,_ = model(inputs, states)\n",
        "            loss = loss_fn(outputs, targets) \n",
        "\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "        \n",
        "            clip_grad_norm_(model.parameters(),0.1)\n",
        "            optimizer.step()\n",
        "        \n",
        "            print(\"Epoch [{}/{}], Loss: {:.4f}\".format(i, 10, loss.item()))       "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/10], Loss: 0.6620\n",
            "Epoch [25/10], Loss: 1.0300\n",
            "Epoch [50/10], Loss: 0.8499\n",
            "Epoch [75/10], Loss: 0.9297\n",
            "Epoch [100/10], Loss: 0.6890\n",
            "Epoch [0/10], Loss: 0.5675\n",
            "Epoch [25/10], Loss: 0.7744\n",
            "Epoch [50/10], Loss: 0.6840\n",
            "Epoch [75/10], Loss: 0.7381\n",
            "Epoch [100/10], Loss: 0.5243\n",
            "Epoch [0/10], Loss: 0.4915\n",
            "Epoch [25/10], Loss: 0.4961\n",
            "Epoch [50/10], Loss: 0.5328\n",
            "Epoch [75/10], Loss: 0.5148\n",
            "Epoch [100/10], Loss: 0.3825\n",
            "Epoch [0/10], Loss: 0.4250\n",
            "Epoch [25/10], Loss: 0.3722\n",
            "Epoch [50/10], Loss: 0.3765\n",
            "Epoch [75/10], Loss: 0.3035\n",
            "Epoch [100/10], Loss: 0.2819\n",
            "Epoch [0/10], Loss: 0.2472\n",
            "Epoch [25/10], Loss: 0.2683\n",
            "Epoch [50/10], Loss: 0.2382\n",
            "Epoch [75/10], Loss: 0.1558\n",
            "Epoch [100/10], Loss: 0.1612\n",
            "Epoch [0/10], Loss: 0.1456\n",
            "Epoch [25/10], Loss: 0.1117\n",
            "Epoch [50/10], Loss: 0.0879\n",
            "Epoch [75/10], Loss: 0.0709\n",
            "Epoch [100/10], Loss: 0.0718\n",
            "Epoch [0/10], Loss: 0.0371\n",
            "Epoch [25/10], Loss: 0.0656\n",
            "Epoch [50/10], Loss: 0.0759\n",
            "Epoch [75/10], Loss: 0.0381\n",
            "Epoch [100/10], Loss: 0.0319\n",
            "Epoch [0/10], Loss: 0.0144\n",
            "Epoch [25/10], Loss: 0.0393\n",
            "Epoch [50/10], Loss: 0.0735\n",
            "Epoch [75/10], Loss: 0.0457\n",
            "Epoch [100/10], Loss: 0.0731\n",
            "Epoch [0/10], Loss: 0.0175\n",
            "Epoch [25/10], Loss: 0.0437\n",
            "Epoch [50/10], Loss: 0.0247\n",
            "Epoch [75/10], Loss: 0.0694\n",
            "Epoch [100/10], Loss: 0.0465\n",
            "Epoch [0/10], Loss: 0.0243\n",
            "Epoch [25/10], Loss: 0.0439\n",
            "Epoch [50/10], Loss: 0.0156\n",
            "Epoch [75/10], Loss: 0.0302\n",
            "Epoch [100/10], Loss: 0.0254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFMlK_K4xSeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "fe1b0547-745e-4124-97fd-f3231ed81bc1"
      },
      "source": [
        "batch_size = 2\n",
        "test_inputs = torch.tensor(x_train[0:timesteps*batch_size,:])\n",
        "test_inputs = test_inputs.view(timesteps,batch_size,-1)\n",
        "print(test_inputs.size())\n",
        "\n",
        "targets = torch.tensor(y_train[0:timesteps*batch_size,:])\n",
        "targets = targets.view(timesteps,batch_size,-1)\n",
        "print(targets.size())\n",
        "    \n",
        "new_states = (torch.zeros(num_layers*num_directions,batch_size,1024),\n",
        "          torch.zeros(num_directions*num_layers,batch_size,1024))\n",
        "\n",
        "\n",
        "outputs,_ = model(test_inputs, new_states)\n",
        "print('outputs:',outputs)\n",
        "print('targets:',targets)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2, 6])\n",
            "torch.Size([5, 2, 4])\n",
            "outputs: tensor([[[ 0.2367, -0.9234, -0.1610,  0.9299],\n",
            "         [-0.0368,  1.0571,  0.1748, -1.0366]],\n",
            "\n",
            "        [[ 0.2056,  1.0955, -0.0589, -1.0945],\n",
            "         [ 0.4798, -0.9640, -0.3664,  0.9844]],\n",
            "\n",
            "        [[ 0.3393, -0.8912, -0.1151,  0.9273],\n",
            "         [ 0.0212, -0.8334,  0.2355,  0.8607]],\n",
            "\n",
            "        [[-0.2129,  1.0500,  0.5570, -1.0057],\n",
            "         [ 0.0255, -1.0316,  0.2056,  1.0573]],\n",
            "\n",
            "        [[-0.2341,  0.8849,  0.6128, -0.8092],\n",
            "         [ 0.0287, -1.0813,  0.2453,  1.1211]]], grad_fn=<ViewBackward>)\n",
            "targets: tensor([[[ 0.2264, -0.8743, -0.0813,  0.9267],\n",
            "         [-0.0452,  1.1466,  0.2553, -1.0886]],\n",
            "\n",
            "        [[ 0.2259,  1.1461, -0.0721, -1.0817],\n",
            "         [ 0.4969, -0.8748, -0.3972,  0.9342]],\n",
            "\n",
            "        [[ 0.2252, -0.8745, -0.0582,  0.9286],\n",
            "         [-0.0465, -0.8745,  0.2790,  0.9293]],\n",
            "\n",
            "        [[-0.3181,  1.1460,  0.6165, -1.0789],\n",
            "         [-0.0472, -0.8759,  0.2923,  0.9497]],\n",
            "\n",
            "        [[-0.3192,  1.1445,  0.6364, -1.0570],\n",
            "         [-0.0487, -0.8772,  0.3194,  0.9702]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuOH1LbAR9nJ",
        "colab_type": "text"
      },
      "source": [
        "# Sequence with a single sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bf2_65BNRRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class state_predictor(nn.Module):\n",
        "  def __init__(self,input_size, hidden_state_size,output_size):\n",
        "    super(state_predictor, self).__init__()\n",
        "    \n",
        "    self.lstm=nn.LSTM(input_size,hidden_state_size)\n",
        "    self.linear=nn.Linear(hidden_state_size, output_size)\n",
        "\n",
        "  def forward(self,x,h):\n",
        "    # h: hidden_state, c=output\n",
        "    # x= x.view(batch_size,timesteps,embed_size)\n",
        "    #print(h[0].shape)\n",
        "    out,(h,c)=self.lstm(x,h)\n",
        "    #print(out.size())\n",
        "    #(batch_size*timesteps, hidden_size)\n",
        "    #out.size(0):batch_size; out.size(1):timesteps, out.size(2): hidden_size\n",
        "    out=out.reshape(out.size(0)*out.size(1),out.size(2)) # flattens the matrix\n",
        "    #print('post reshape',out.size())\n",
        "    # decode hidden states of all time steps\n",
        "    out= self.linear(out)\n",
        "    #print(out.size())\n",
        "    return out, (h,c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTFyDNOaR9Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for it in range(10):\n",
        "    for i in range(0,len(x_train), timesteps):\n",
        "        if len(x_train) > i + timesteps:\n",
        "            x = x_train[i:i+timesteps,:]\n",
        "            y = y_train[i:i+timesteps,:]\n",
        "\n",
        "            inputs = torch.tensor(x)\n",
        "            inputs = inputs.view(timesteps,batch_size,-1)\n",
        "\n",
        "            targets = torch.tensor(y)\n",
        "\n",
        "            states = (torch.zeros(1,batch_size,hidden_size),\n",
        "                  torch.zeros(1,batch_size,hidden_size))\n",
        "\n",
        "            outputs,_ = model(inputs, states)\n",
        "            loss = loss_fn(outputs, targets) \n",
        "\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "        \n",
        "            clip_grad_norm_(model.parameters(),0.1)\n",
        "            optimizer.step()\n",
        "        \n",
        "            print(\"Epoch [{}/{}], Loss: {:.4f}\".format(i, 10, loss.item()))       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW_7ke4fiNxZ",
        "colab_type": "code",
        "outputId": "99a49a13-b835-434e-9089-a122e944bc19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "test_input = torch.tensor(x_train[0:timesteps,:])\n",
        "test_input = test_input.view(timesteps,1,-1)\n",
        "\n",
        "print(test_input.size())\n",
        "targets = torch.tensor(y_train[0:timesteps,:])\n",
        "#targets = targets.view(1,1,-1)\n",
        "print(targets.size())\n",
        "    \n",
        "new_states = (torch.zeros(1,1,1024),\n",
        "          torch.zeros(1,1,1024))\n",
        "\n",
        "\n",
        "\n",
        "outputs,_ = model(test_input, new_states)\n",
        "print('outputs:',outputs)\n",
        "print('targets:',targets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 6])\n",
            "torch.Size([5, 4])\n",
            "torch.Size([1, 1, 1024])\n",
            "torch.Size([1, 1024])\n",
            "outputs: tensor([[-0.1105, -1.0144,  0.0497,  0.9935],\n",
            "        [-0.5606,  1.0792,  0.4549, -1.0844],\n",
            "        [-0.2443,  0.9342,  0.1536, -0.9413],\n",
            "        [ 0.3207,  1.0246, -0.3347, -1.0304],\n",
            "        [ 0.9182,  1.0647, -0.8020, -1.0675]], grad_fn=<AddmmBackward>)\n",
            "targets: tensor([[-0.1773, -1.0489, -0.0194,  1.0251],\n",
            "        [-0.6346,  0.9543,  0.3945, -0.9710],\n",
            "        [-0.1765,  0.9539, -0.0303, -0.9656],\n",
            "        [ 0.2815,  0.9540, -0.4530, -0.9665],\n",
            "        [ 0.7394,  0.9544, -0.8760, -0.9737]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2L4f98xRx2G",
        "colab_type": "text"
      },
      "source": [
        "# Batch samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebl2ZT7cMQZb",
        "colab_type": "code",
        "outputId": "f7b07a9e-7b26-42d1-d57f-e2bef51999bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for it in range(10):\n",
        "    for mb in range(0,len(x_train), batch_size): # Nawid- Batch size is the step size\n",
        "        if len(x_train) > mb + batch_size:\n",
        "            x_mb = x_train[mb:mb+batch_size,:]\n",
        "            y_mb = y_train[mb:mb+batch_size,:]\n",
        "\n",
        "            inputs = torch.tensor(x_mb)\n",
        "            inputs = inputs.view(1,batch_size,-1)\n",
        "\n",
        "            targets = torch.tensor(y_mb)\n",
        "            #targets = targets.view(1,batch_size,-1)\n",
        "\n",
        "            states = (torch.zeros(1,batch_size,hidden_size),\n",
        "                  torch.zeros(1,batch_size,hidden_size))\n",
        "    \n",
        "            outputs,_ = model(inputs, states)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "        \n",
        "            clip_grad_norm_(model.parameters(),0.1)\n",
        "            optimizer.step()\n",
        "        \n",
        "\n",
        "            print(\"Epoch [{}/{}], Loss: {:.4f}\".format(i, 10, loss.item()))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [160/10], Loss: 0.0048\n",
            "Epoch [160/10], Loss: 0.0045\n",
            "Epoch [160/10], Loss: 0.0032\n",
            "Epoch [160/10], Loss: 0.0074\n",
            "Epoch [160/10], Loss: 0.0265\n",
            "Epoch [160/10], Loss: 0.0171\n",
            "Epoch [160/10], Loss: 0.0080\n",
            "Epoch [160/10], Loss: 0.0306\n",
            "Epoch [160/10], Loss: 0.0026\n",
            "Epoch [160/10], Loss: 0.0029\n",
            "Epoch [160/10], Loss: 0.0091\n",
            "Epoch [160/10], Loss: 0.0191\n",
            "Epoch [160/10], Loss: 0.0045\n",
            "Epoch [160/10], Loss: 0.0104\n",
            "Epoch [160/10], Loss: 0.0123\n",
            "Epoch [160/10], Loss: 0.0030\n",
            "Epoch [160/10], Loss: 0.0051\n",
            "Epoch [160/10], Loss: 0.0068\n",
            "Epoch [160/10], Loss: 0.0064\n",
            "Epoch [160/10], Loss: 0.0070\n",
            "Epoch [160/10], Loss: 0.0062\n",
            "Epoch [160/10], Loss: 0.0089\n",
            "Epoch [160/10], Loss: 0.0103\n",
            "Epoch [160/10], Loss: 0.0134\n",
            "Epoch [160/10], Loss: 0.0015\n",
            "Epoch [160/10], Loss: 0.0014\n",
            "Epoch [160/10], Loss: 0.0078\n",
            "Epoch [160/10], Loss: 0.0183\n",
            "Epoch [160/10], Loss: 0.0019\n",
            "Epoch [160/10], Loss: 0.0038\n",
            "Epoch [160/10], Loss: 0.0033\n",
            "Epoch [160/10], Loss: 0.0030\n",
            "Epoch [160/10], Loss: 0.0045\n",
            "Epoch [160/10], Loss: 0.0039\n",
            "Epoch [160/10], Loss: 0.0042\n",
            "Epoch [160/10], Loss: 0.0033\n",
            "Epoch [160/10], Loss: 0.0075\n",
            "Epoch [160/10], Loss: 0.0143\n",
            "Epoch [160/10], Loss: 0.0065\n",
            "Epoch [160/10], Loss: 0.0187\n",
            "Epoch [160/10], Loss: 0.0027\n",
            "Epoch [160/10], Loss: 0.0029\n",
            "Epoch [160/10], Loss: 0.0118\n",
            "Epoch [160/10], Loss: 0.0291\n",
            "Epoch [160/10], Loss: 0.0043\n",
            "Epoch [160/10], Loss: 0.0029\n",
            "Epoch [160/10], Loss: 0.0095\n",
            "Epoch [160/10], Loss: 0.0125\n",
            "Epoch [160/10], Loss: 0.0058\n",
            "Epoch [160/10], Loss: 0.0068\n",
            "Epoch [160/10], Loss: 0.0029\n",
            "Epoch [160/10], Loss: 0.0059\n",
            "Epoch [160/10], Loss: 0.0316\n",
            "Epoch [160/10], Loss: 0.0300\n",
            "Epoch [160/10], Loss: 0.0099\n",
            "Epoch [160/10], Loss: 0.0046\n",
            "Epoch [160/10], Loss: 0.0012\n",
            "Epoch [160/10], Loss: 0.0041\n",
            "Epoch [160/10], Loss: 0.0076\n",
            "Epoch [160/10], Loss: 0.0098\n",
            "Epoch [160/10], Loss: 0.0070\n",
            "Epoch [160/10], Loss: 0.0184\n",
            "Epoch [160/10], Loss: 0.0207\n",
            "Epoch [160/10], Loss: 0.0098\n",
            "Epoch [160/10], Loss: 0.0089\n",
            "Epoch [160/10], Loss: 0.0089\n",
            "Epoch [160/10], Loss: 0.0057\n",
            "Epoch [160/10], Loss: 0.0051\n",
            "Epoch [160/10], Loss: 0.0034\n",
            "Epoch [160/10], Loss: 0.0066\n",
            "Epoch [160/10], Loss: 0.0087\n",
            "Epoch [160/10], Loss: 0.0127\n",
            "Epoch [160/10], Loss: 0.0053\n",
            "Epoch [160/10], Loss: 0.0035\n",
            "Epoch [160/10], Loss: 0.0133\n",
            "Epoch [160/10], Loss: 0.0544\n",
            "Epoch [160/10], Loss: 0.0026\n",
            "Epoch [160/10], Loss: 0.0043\n",
            "Epoch [160/10], Loss: 0.0038\n",
            "Epoch [160/10], Loss: 0.0065\n",
            "Epoch [160/10], Loss: 0.0056\n",
            "Epoch [160/10], Loss: 0.0051\n",
            "Epoch [160/10], Loss: 0.0045\n",
            "Epoch [160/10], Loss: 0.0171\n",
            "Epoch [160/10], Loss: 0.0053\n",
            "Epoch [160/10], Loss: 0.0165\n",
            "Epoch [160/10], Loss: 0.0181\n",
            "Epoch [160/10], Loss: 0.0251\n",
            "Epoch [160/10], Loss: 0.0027\n",
            "Epoch [160/10], Loss: 0.0044\n",
            "Epoch [160/10], Loss: 0.0050\n",
            "Epoch [160/10], Loss: 0.0209\n",
            "Epoch [160/10], Loss: 0.0055\n",
            "Epoch [160/10], Loss: 0.0070\n",
            "Epoch [160/10], Loss: 0.0062\n",
            "Epoch [160/10], Loss: 0.0067\n",
            "Epoch [160/10], Loss: 0.0035\n",
            "Epoch [160/10], Loss: 0.0041\n",
            "Epoch [160/10], Loss: 0.0026\n",
            "Epoch [160/10], Loss: 0.0141\n",
            "Epoch [160/10], Loss: 0.0282\n",
            "Epoch [160/10], Loss: 0.0201\n",
            "Epoch [160/10], Loss: 0.0109\n",
            "Epoch [160/10], Loss: 0.0173\n",
            "Epoch [160/10], Loss: 0.0009\n",
            "Epoch [160/10], Loss: 0.0015\n",
            "Epoch [160/10], Loss: 0.0045\n",
            "Epoch [160/10], Loss: 0.0160\n",
            "Epoch [160/10], Loss: 0.0058\n",
            "Epoch [160/10], Loss: 0.0181\n",
            "Epoch [160/10], Loss: 0.0199\n",
            "Epoch [160/10], Loss: 0.0035\n",
            "Epoch [160/10], Loss: 0.0051\n",
            "Epoch [160/10], Loss: 0.0051\n",
            "Epoch [160/10], Loss: 0.0032\n",
            "Epoch [160/10], Loss: 0.0033\n",
            "Epoch [160/10], Loss: 0.0037\n",
            "Epoch [160/10], Loss: 0.0073\n",
            "Epoch [160/10], Loss: 0.0086\n",
            "Epoch [160/10], Loss: 0.0112\n",
            "Epoch [160/10], Loss: 0.0017\n",
            "Epoch [160/10], Loss: 0.0021\n",
            "Epoch [160/10], Loss: 0.0054\n",
            "Epoch [160/10], Loss: 0.0138\n",
            "Epoch [160/10], Loss: 0.0019\n",
            "Epoch [160/10], Loss: 0.0024\n",
            "Epoch [160/10], Loss: 0.0021\n",
            "Epoch [160/10], Loss: 0.0033\n",
            "Epoch [160/10], Loss: 0.0052\n",
            "Epoch [160/10], Loss: 0.0057\n",
            "Epoch [160/10], Loss: 0.0043\n",
            "Epoch [160/10], Loss: 0.0165\n",
            "Epoch [160/10], Loss: 0.0068\n",
            "Epoch [160/10], Loss: 0.0048\n",
            "Epoch [160/10], Loss: 0.0095\n",
            "Epoch [160/10], Loss: 0.0087\n",
            "Epoch [160/10], Loss: 0.0019\n",
            "Epoch [160/10], Loss: 0.0031\n",
            "Epoch [160/10], Loss: 0.0040\n",
            "Epoch [160/10], Loss: 0.0177\n",
            "Epoch [160/10], Loss: 0.0065\n",
            "Epoch [160/10], Loss: 0.0162\n",
            "Epoch [160/10], Loss: 0.0150\n",
            "Epoch [160/10], Loss: 0.0117\n",
            "Epoch [160/10], Loss: 0.0037\n",
            "Epoch [160/10], Loss: 0.0022\n",
            "Epoch [160/10], Loss: 0.0034\n",
            "Epoch [160/10], Loss: 0.0032\n",
            "Epoch [160/10], Loss: 0.0057\n",
            "Epoch [160/10], Loss: 0.0049\n",
            "Epoch [160/10], Loss: 0.0044\n",
            "Epoch [160/10], Loss: 0.0024\n",
            "Epoch [160/10], Loss: 0.0012\n",
            "Epoch [160/10], Loss: 0.0019\n",
            "Epoch [160/10], Loss: 0.0039\n",
            "Epoch [160/10], Loss: 0.0064\n",
            "Epoch [160/10], Loss: 0.0013\n",
            "Epoch [160/10], Loss: 0.0027\n",
            "Epoch [160/10], Loss: 0.0051\n",
            "Epoch [160/10], Loss: 0.0039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0OySW-6SwjL",
        "colab_type": "code",
        "outputId": "d663a39e-0b33-4a23-fe7f-5e1632cb0b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "test_input = torch.tensor(x_train[1,:])\n",
        "test_input = test_input.view(1,1,-1)\n",
        "\n",
        "print(test_input.size())\n",
        "targets = torch.tensor(y_train[1,:])\n",
        "targets = targets.view(1,1,-1)\n",
        "print(targets.size())\n",
        "    \n",
        "new_states = (torch.zeros(1,1,1024),\n",
        "          torch.zeros(1,1,1024))\n",
        "\n",
        "\n",
        "\n",
        "outputs,_ = model(test_input, new_states)\n",
        "print('outputs:',outputs)\n",
        "print('targets:',targets)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 6])\n",
            "torch.Size([1, 1, 4])\n",
            "outputs: tensor([[-0.5882,  0.9145,  0.4274, -0.9325]], grad_fn=<AddmmBackward>)\n",
            "targets: tensor([[[-0.6346,  0.9543,  0.3945, -0.9710]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdooY4UJFT2-",
        "colab_type": "text"
      },
      "source": [
        "# SINGLE SAMPLE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCz2bpQYSMZR",
        "colab_type": "code",
        "outputId": "3b28e5ae-17ba-4e28-e1aa-aede88eeb667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "for i in range(len(x_train)):\n",
        "    \n",
        "    inputs = torch.tensor(x_train[i,:])\n",
        "    #print(inputs.dtype)\n",
        "    inputs = inputs.view(1,1,-1)\n",
        "    \n",
        "    targets = torch.tensor(y_train[i,:])\n",
        "    targets = targets.view(1,1,-1)\n",
        "    #print('targets:', targets.size())\n",
        "    \n",
        "    \n",
        "    states = (torch.zeros(1,1,1024),\n",
        "              torch.zeros(1,1,1024))\n",
        "\n",
        "    outputs,_ = model(inputs, states)\n",
        "    #print('outputs:',outputs.size())\n",
        "    #print('targets:',targets.size())\n",
        "    loss = loss_fn(outputs, targets.reshape(1,-1))\n",
        "\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "        \n",
        "    clip_grad_norm_(model.parameters(),0.1)\n",
        "    step = (i+1)\n",
        "    if step % 10 ==0:\n",
        "        print(\"Epoch [{}/{}], Loss: {:.4f}\".format(i, 10, loss.item()))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [9/10], Loss: 0.2790\n",
            "Epoch [19/10], Loss: 0.0826\n",
            "Epoch [29/10], Loss: 0.0048\n",
            "Epoch [39/10], Loss: 0.0247\n",
            "Epoch [49/10], Loss: 0.0596\n",
            "Epoch [59/10], Loss: 0.0397\n",
            "Epoch [69/10], Loss: 0.0165\n",
            "Epoch [79/10], Loss: 0.0847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSqj8xEHlYK_",
        "colab_type": "code",
        "outputId": "427ced1b-71c8-4c27-ad1f-46f9bd134f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)\n",
        "obs = env.reset()\n",
        "obs_list = []\n",
        "print(obs.shape)\n",
        "obs_list.append(obs)\n",
        "obs_values = np.array([obs for obs in obs_list])\n",
        "print(obs_values.shape)\n",
        "action = env.action_space.sample()\n",
        "action_one_hot = one_hot(action)\n",
        "print(action_one_hot.shape)\n",
        "action_list = []\n",
        "action_list.append(action_one_hot)\n",
        "action_values = np.array([act for act in action_list])\n",
        "print(action_values.shape)\n",
        "state =  np.concatenate((obs_values, action_values),axis =1 )\n",
        "state.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4,)\n",
            "(1, 4)\n",
            "(2,)\n",
            "(1, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WCScyREgBgQ",
        "colab_type": "code",
        "outputId": "327fe99d-e9ce-4b6b-eb4f-7e27b4806292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "state = state.reshape(1,1,6)\n",
        "state_input = torch.tensor(state)\n",
        "lstm = nn.LSTM(6,6)\n",
        "state_input = state_input.view(len(state_input),1,-1)\n",
        "hidden = (torch.randn(1,1,6), torch.randn(1,1,6))\n",
        "out, hidden = lstm(state_input.float(), hidden)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0386,  0.1876, -0.0047, -0.1450, -0.0882,  0.2597]]],\n",
            "       grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJlAwy93cBqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(obs) # shows 4 different values\n",
        "inputs = obs.reshape(1,1,4) # sequence size, batch size, and feature size\n",
        "inputs = torch.tensor(inputs)\n",
        "lstm = nn.LSTM(4, 4)  # Input dim is 4, output dim is 4\n",
        "inputs = inputs.view(len(inputs),1,-1)\n",
        "#print(inputs.size())\n",
        "lstm = lstm.float()\n",
        "hidden = (torch.randn(1,1,4), torch.randn(1,1,4))\n",
        "out, hidden = lstm(inputs.float(), hidden)\n",
        "print(hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etWChYG5cE4Y",
        "colab_type": "text"
      },
      "source": [
        "# Initial practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr4MrPNllGBm",
        "colab_type": "code",
        "outputId": "1b8eabda-b985-4254-ec79-4fa5ead8ff2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
        "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
        "\n",
        "# initialize the hidden state.\n",
        "hidden = (torch.randn(1, 1, 3),\n",
        "          torch.randn(1, 1, 3)) # I believe there is 2 different sets of values since this is a lstm and so there are values for the hidden state as well as well as the cell state\n",
        "for i in inputs:\n",
        "    # Step through the sequence one element at a time.\n",
        "    # after each step, hidden contains the hidden state.\n",
        "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
        "    # alternatively we can do the entire sequence all at once\n",
        "    # The first value returned by LSTM is all the hidden states throughout the sequence\n",
        "    # the second isjust the most recent hidden state\n",
        "\n",
        "\n",
        "\n",
        "inputs = torch.cat(inputs).view(len(inputs),1,-1)\n",
        "hidden = (torch.randn(1,1,3), torch.randn(1,1,3)) # reset hidden state\n",
        "out, hidden  = lstm(inputs, hidden)\n",
        "print('out:',out)\n",
        "print('hidden:',hidden)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out: tensor([[[ 3.3281e-04, -3.4894e-01,  2.0808e-01]],\n",
            "\n",
            "        [[ 1.5697e-01, -6.1789e-02,  1.4116e-01]],\n",
            "\n",
            "        [[ 1.4011e-01, -1.3284e-01,  7.2157e-02]],\n",
            "\n",
            "        [[ 2.9385e-02, -1.7298e-01,  2.4809e-02]],\n",
            "\n",
            "        [[ 1.7907e-01, -2.5394e-01,  3.5012e-02]]], grad_fn=<StackBackward>)\n",
            "hidden: (tensor([[[ 0.1791, -0.2539,  0.0350]]], grad_fn=<StackBackward>), tensor([[[ 0.6383, -0.4234,  0.0539]]], grad_fn=<StackBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HtHU_Tfb5aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9cgDpLdTIoY",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHU1h8GsP7wC",
        "colab_type": "code",
        "outputId": "608af329-9fa3-4f2e-c023-62662a4be2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "training_data = [\n",
        "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
        "]\n",
        "\n",
        "word_to_ix = {}\n",
        "for sent, tags in training_data:\n",
        "    for word in sent: #  looks at the words in the sentence \n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix) #  This adds a new word into the dictionary as well as adding as add a value for it\n",
        "print(word_to_ix)\n",
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
        "\n",
        "# These will usually be more like 32 or 64 dimensional.\n",
        "# We will keep them small, so we can see how the weights change as we train.\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "\n",
        "\n",
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger,self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs,and outputs hidden states\n",
        "        # with dimensionality hidden  dim\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim. tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence) # changes the sentence to word embeddings\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence),1,-1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence),-1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpmCeI74Ti5C",
        "colab_type": "code",
        "outputId": "3ca90102-1ccf-4e46-add4-a7e8986f4c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGB(model.parameters(), lr = 0.1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    tag_scores = model(inputs)\n",
        "    print(tag_scores)\n",
        "\n",
        "for epoch in range(300):\n",
        "    for sentence, tags in training_data:\n",
        "        # Step 1. Remember that Pytorch accumulates gradients\n",
        "        # we need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. get our inputs ready for the network, that is, turn them into tensors of word indices\n",
        "        # Tensors of word indices\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "        # Step 3. Run our forward pass\n",
        "        tag_scores = model(sentence_in)\n",
        "\n",
        "        #Step 4. Compute the loss, gradients, and update the parameters by calling optimizer.step()\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f85c6f8afd67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-91988e026ccc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embedding_dim, hidden_dim, vocab_size, tagset_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# The linear layer that maps from hidden state space to tag space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mtagset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'tagset_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqTNZzIuZJQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}