{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embed_2_contrast_180520.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Q6uZbUKVLi-eeyQrWd1BEo-QpAnE_92w",
      "authorship_tag": "ABX9TyM+qN+u83XA3HxGvs6yOSf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerdk312/Model-based-RL/blob/master/Embed_2_contrast_200520_MSE_error.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57XVXKX0pUf7",
        "colab_type": "code",
        "outputId": "c3818d86-57d5-4036-cfbc-a8124762f702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install git+git://github.com/openai/baselines\n",
        "!pip install wandb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/openai/baselines\n",
            "  Cloning git://github.com/openai/baselines to /tmp/pip-req-build-ujiwaour\n",
            "  Running command git clone -q git://github.com/openai/baselines /tmp/pip-req-build-ujiwaour\n",
            "Collecting gym<0.16.0,>=0.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/01/8771e8f914a627022296dab694092a11a7d417b6c8364f0a44a8debca734/gym-0.15.7.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (0.15.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from baselines==0.1.6) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym<0.16.0,>=0.15.4->baselines==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.16.0,>=0.15.4->baselines==0.1.6) (0.16.0)\n",
            "Building wheels for collected packages: baselines, gym\n",
            "  Building wheel for baselines (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for baselines: filename=baselines-0.1.6-cp36-none-any.whl size=220664 sha256=c3533eeaa80f2dcb1a83019bc637cc932a632cb5dc0829bc091efd9501f59926\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k4yi3do8/wheels/42/1c/91/28314e0cd1d2cc57cf8dd18b20c4c9a0f39ae518adc13caf24\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.7-cp36-none-any.whl size=1648840 sha256=8bc5698ec6c5ba3a943295b1a9b1b6c473d0b7cc287dce7ab6dbe4cdf03ddc95\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/60/6a/f9c27ae133abaf5a5687ed2fa8ed19627d7fac5d843a27572b\n",
            "Successfully built baselines gym\n",
            "\u001b[31mERROR: gym 0.15.7 has requirement cloudpickle~=1.2.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gym, baselines\n",
            "  Found existing installation: gym 0.17.2\n",
            "    Uninstalling gym-0.17.2:\n",
            "      Successfully uninstalled gym-0.17.2\n",
            "Successfully installed baselines-0.1.6 gym-0.15.7\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/c7/8bf2c62c3f133f45e135a8a116e4e0f162043248e3db54de30996eaf1a8a/wandb-0.8.36-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.9MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 30.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.3MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/95/9a20eebcedab2c1c63fad59fe19a0469edfc2a25b8576497e8084629c2ff/sentry_sdk-0.14.4-py2.py3-none-any.whl (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 35.3MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.3MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25hCollecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: gql, watchdog, subprocess32, graphql-core, pathtools\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=b6c3c66ecbc8ab6ee9a5698bdb76dd5077d6581d8543e3e5654aa8b7a3e5ae02\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=6d0f8f00fa02987c57abe1254845d2fc6bf86d08ad127644c9372b8df7d82211\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=e2809677fd32735b2dbf7f7655b648ff39a6ba38c8dbb70edc5fb5396710e0c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=ac1c2d04356868704e0c9bcbe1703a7db5ddfacd6c1f89df8ac486eff2b9edf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=2c18ed5ba64b890e0148d0c30df4a534c2674c04eaa9141c1b47f869c50f4c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built gql watchdog subprocess32 graphql-core pathtools\n",
            "Installing collected packages: smmap, gitdb, GitPython, graphql-core, gql, configparser, pathtools, watchdog, sentry-sdk, docker-pycreds, subprocess32, shortuuid, wandb\n",
            "Successfully installed GitPython-3.1.2 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.14.4 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.8.36 watchdog-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp0jzlXIcFfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "#sys.path.append('/content/drive/My Drive')\n",
        "sys.path.append('/content/drive/My Drive/Embed_2_Contrast')\n",
        "import wandb\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gym\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from custom_wrappers import custom_wrapper\n",
        "from encoder import make_encoder\n",
        "from earlystopping import EarlyStopping_loss\n",
        "from generalfunctions import General_functions\n",
        "from utils import make_dir, random_crop,center_crop_image, soft_update_params, weight_init, random_color_jitter\n",
        "from torch.autograd import Variable\n",
        "from datacollection import Data_collection\n",
        "from models import CURL, Dynamics_model\n",
        "from replay_buffer import ReplayBuffer\n",
        "\n",
        "# Needed to create dataloaders\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e92c4vhjVZX",
        "colab_type": "code",
        "outputId": "7efc5460-fb4d-4fc3-83aa-015a80872d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!wandb login #############"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDaFHhxLacNp",
        "colab_type": "text"
      },
      "source": [
        "# CURL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZFr4dPIjcLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CurlAgent(object):\n",
        "    ''' CURL representation learning'''\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_shape,\n",
        "        device,\n",
        "        frames, \n",
        "        encoder_lr = 1e-4,\n",
        "        encoder_tau = 0.001,\n",
        "        encoder_feature_dim = 50, # This is the size of the embedding used for the\n",
        "        dynamics_hidden_dim = 256,\n",
        "        downsample = True,\n",
        "        cpc_update_freq=1,\n",
        "        encoder_update_freq = 1,\n",
        "        random_jitter = True,\n",
        "        detach_encoder=True,\n",
        "        dyn_update_freq= 2        \n",
        "    ):\n",
        "        self.device = device\n",
        "        self.cpc_update_freq = cpc_update_freq\n",
        "        self.image_size = obs_shape[-2] # Changed this to the numpy dimension\n",
        "        self.frames = frames\n",
        "        self.detach_encoder =  detach_encoder\n",
        "\n",
        "        self.encoder_tau = encoder_tau\n",
        "        self.epoch_step = 0\n",
        "        self.encoder_update_freq = encoder_update_freq\n",
        "        self.random_jitter = random_jitter\n",
        "        \n",
        "        self.CURL = CURL(obs_shape, encoder_feature_dim,\n",
        "                         encoder_feature_dim,downsample = downsample).to(self.device)\n",
        "        \n",
        "        self.Model = Dynamics_model(self.CURL.encoder, encoder_feature_dim,\n",
        "                                    hidden_dim=dynamics_hidden_dim).to(self.device)\n",
        "        \n",
        "        self.cpc_optimizer = torch.optim.Adam(\n",
        "                self.CURL.parameters(), lr=encoder_lr\n",
        "            )\n",
        "        self.dynamics_optimizer = torch.optim.Adam(\n",
        "            self.Model.parameters(), lr =encoder_lr \n",
        "        )\n",
        "\n",
        "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
        "        self.MSE_loss = nn.MSELoss() # Nawid - Added this loss for the prediction\n",
        "        self.train()\n",
        "    \n",
        "    def train(self, training = True):\n",
        "        self.training = training\n",
        "        self.CURL.train(training)\n",
        "        self.Model.train(training)\n",
        "\n",
        "    def update(self, train_dataloader,val_dataloader,early_stopper_contrastive, early_stopper_dynamics):\n",
        "        #torch.cuda.empty_cache() # Releases cache so the GPU has more memory\n",
        "        if early_stopper_contrastive.early_stop or early_stopper_dynamics.early_stop:\n",
        "            print('early stopping-Early stopping contrastive, Early stopping dynamics :',early_stopper_contrastive.early_stop, early_stopper_dynamics.early_stop)\n",
        "            return\n",
        "\n",
        "        for step, (obs, actions, next_obs, cpc_kwargs) in enumerate(train_dataloader):\n",
        "            if step % self.encoder_update_freq == 0:\n",
        "                soft_update_params(\n",
        "                    self.CURL.encoder, self.CURL.encoder_target,\n",
        "                    self.encoder_tau\n",
        "                )\n",
        "            if step % self.cpc_update_freq == 0:            \n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                self.update_cpc(obs_anchor, obs_pos) # Nawid -  Performs the contrastive loss I believe\n",
        "                    \n",
        "        self.validation(val_dataloader,early_stopper_contrastive, early_stopper_dynamics)\n",
        "    \n",
        "    def update_cpc(self, obs_anchor, obs_pos):\n",
        "        obs_anchor, obs_pos = obs_anchor.to(self.device), obs_pos.to(self.device)\n",
        "        if self.random_jitter:\n",
        "            obs_anchor, obs_pos = random_color_jitter(obs_anchor,batch_size = obs_anchor.shape[0],frames = self.frames), random_color_jitter(obs_pos,batch_size = obs_pos.shape[0],frames= self.frames)\n",
        "\n",
        "        z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "        z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "\n",
        "        logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "        labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "        loss = self.cross_entropy_loss(logits, labels)\n",
        "        wandb.log({'Contrastive Training loss':loss.item()})\n",
        "\n",
        "        self.cpc_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.cpc_optimizer.step()  # Nawid - Used to update the cpc\n",
        "    \n",
        "    def update_dynamics(self, obs,actions, next_obs):\n",
        "        obs, actions, next_obs = obs.to(self.device),actions.to(self.device), next_obs.to(device)\n",
        "        \n",
        "        prediced_next_latent = self.Model(obs,actions,detach_encoder = self.detach_encoder) # only trains the fully connected part of the output, features from the encoder are not trained\n",
        "        next_latent = self.CURL.encode(next_obs,detach=True) # no gradients will flow from this output\n",
        "        prediction_loss = self.MSE_loss(prediction,labels)\n",
        "        wandb.log({'Dynamics Training loss':prediction_loss.item()}) #  Need to use .item otherwise the loss will still be kept which will reduce the memory on the GPU\n",
        "\n",
        "        self.dynamics_optimizer.zero_grad()\n",
        "        prediction_loss.backward()\n",
        "        self.dynamics_optimizer.step()\n",
        "    \n",
        "\n",
        "\n",
        "    def validation(self, dataloader,early_stopper_contrastive, early_stopper_dynamics):\n",
        "        epoch_contrastive_loss = 0\n",
        "        epoch_dynamics_loss = 0\n",
        "        self.CURL.eval()\n",
        "        self.Model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (obs, actions, next_obs, cpc_kwargs) in enumerate(dataloader):\n",
        "                obs_anchor, obs_pos = cpc_kwargs[\"obs_anchor\"], cpc_kwargs[\"obs_pos\"]\n",
        "                obs, obs_anchor,obs_pos = obs.to(self.device), obs_anchor.to(self.device), obs_pos.to(self.device)\n",
        "                actions, next_obs = actions.to(self.device), next_obs.to(self.device)\n",
        "                if self.random_jitter:\n",
        "                    obs_anchor, obs_pos =  random_color_jitter(obs_anchor,batch_size = obs_anchor.shape[0],frames = self.frames), random_color_jitter(obs_pos,batch_size = obs_pos.shape[0],frames= self.frames)\n",
        "\n",
        "                ''' Code to check the appearance of the image\n",
        "                image = obs_pos[0]\n",
        "                image = image.permute(1, 2, 0)\n",
        "                plt.imshow(image)\n",
        "                plt.figure()\n",
        "                plt.show()\n",
        "                return \n",
        "                ''' \n",
        "                actions, next_obs = actions.to(self.device), next_obs.to(self.device)\n",
        "                z_a = self.CURL.encode(obs_anchor) # Nawid -  Encode the anchor\n",
        "                z_pos = self.CURL.encode(obs_pos, ema=True) # Nawid- Encode the positive with the momentum encoder\n",
        "                logits = self.CURL.compute_logits(z_a, z_pos) #  Nawid- Compute the logits between them\n",
        "                labels = torch.arange(logits.shape[0]).long().to(self.device)\n",
        "                loss = self.cross_entropy_loss(logits, labels)\n",
        "                epoch_contrastive_loss += loss.item()\n",
        "                \n",
        "                prediced_next_latent = self.Model(obs,actions,detach_encoder = self.detach_encoder) # only trains the fully connected part of the output, features from the encoder are not trained\n",
        "                next_latent = self.CURL.encode(next_obs,detach=True) # no gradients will flow from this output\n",
        "                prediction_loss = self.MSE_loss(prediced_next_latent,next_latent)\n",
        "                epoch_dynamics_loss += prediction_loss.item()\n",
        "\n",
        "            average_epoch_contrastive_loss = epoch_contrastive_loss/(i+1)\n",
        "            average_epoch_dynamics_loss = epoch_dynamics_loss/(i+1)\n",
        "\n",
        "            self.epoch_step += 1 # increase epoch counter\n",
        "            wandb.log({'Contrastive Validation loss':average_epoch_contrastive_loss, 'Dynamics Validation loss':average_epoch_dynamics_loss,'epoch': self.epoch_step})\n",
        "\n",
        "            print('epoch:', self.epoch_step)\n",
        "            early_stopper_contrastive(average_epoch_contrastive_loss,self.CURL,self.cpc_optimizer)\n",
        "            early_stopper_dynamics(average_epoch_dynamics_loss, self.Model, self.dynamics_optimizer)\n",
        "\n",
        "        self.train()\n",
        "    \n",
        "def make_agent(obs_shape, device, dict_info):\n",
        "    return CurlAgent(\n",
        "        obs_shape = obs_shape,\n",
        "        device = device,\n",
        "        frames = dict_info['frames'],\n",
        "        random_jitter = dict_info['random_jitter'],\n",
        "        encoder_update_freq =dict_info['encoder_update_freq'],\n",
        "        dyn_update_freq =dict_info['dynamics_update_freq'],\n",
        "        encoder_feature_dim = dict_info['encoder_feature_dim'], #  size of the embedding from the projection head\n",
        "        encoder_lr = dict_info['encoder_lr'],\n",
        "        encoder_tau = dict_info['encoder_tau'],\n",
        "        downsample = dict_info['downsample'],\n",
        "        dynamics_hidden_dim = dict_info['dynamics_hidden_dim'],\n",
        "        detach_encoder = dict_info['detach_encoder']\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4SvnJeJUgM",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNHK7nCaJT-J",
        "colab_type": "code",
        "outputId": "8cf38640-0faa-4fd2-acc2-0e5466177550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "ENV_NAME = 'MsPacmanDeterministic-v4'\n",
        "n_actions = 4 \n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "no_agents = 5\n",
        "state_space = no_agents*2 \n",
        "parse_dict= {'pre_transform_image_size':100,\n",
        "             'image_size':84,\n",
        "             'frame_stack':False,\n",
        "             'frames': 1,\n",
        "             'state_space':state_space,\n",
        "             'train_capacity':100,#50000,\n",
        "             'val_capacity':100,#20000,\n",
        "             'num_train_epochs':20,\n",
        "             'batch_size':512,\n",
        "             'random_crop': False,\n",
        "             'encoder_update_freq':1,\n",
        "             'dynamics_update_freq':1,\n",
        "             'encoder_feature_dim':128,\n",
        "             'dynamics_hidden_dim': 256,\n",
        "             'encoder_lr':1e-3,\n",
        "             'encoder_tau':0.05, # value used for atari experiments in curl\n",
        "             'downsample':True,\n",
        "             'encoder_type':'Impala',\n",
        "             'grayscale': False,\n",
        "             'load_pretrain_model': False,\n",
        "             'walls_present':True,\n",
        "             'pretrain_model':False,\n",
        "             'save_data':False,\n",
        "             'num_pretrain_epochs':25,\n",
        "             'transform': data_transform,\n",
        "             'random_jitter':True,\n",
        "             'detach_encoder':True\n",
        "            }\n",
        "\n",
        "#custom_name = 'rand_crop-' +str(parse_dict['random_crop'])  + '_gray-' + str(parse_dict['grayscale']) + '_walls-' +str(parse_dict['walls_present'])  + '_pretrain-' + str(parse_dict['pretrain_model'])\n",
        "custom_name = 'Contrastive_hp_testing_random_jitter-'+str(parse_dict['random_jitter']) + '_encoder_tau-' +str(parse_dict['encoder_tau']) \n",
        "wandb.init(entity=\"nerdk312\",name=custom_name, project=\"Embed2Contrast\",config = parse_dict)\n",
        "\n",
        "possible_positions = np.load('/content/drive/My Drive/MsPacman-data/possible_pacman_positions.npy',allow_pickle=True)\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "if parse_dict['load_pretrain_model']:\n",
        "    config.pretrained_model = pretrain_model_dir\n",
        "\n",
        "# Data collection\n",
        "data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity'])\n",
        "val_data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict, parse_dict['val_capacity'])\n",
        "\n",
        "data_object.gather_random_trajectories(5000)\n",
        "val_data_object.gather_random_trajectories(5000)\n",
        "\n",
        "data_object.replay_buffer.crop_control(parse_dict['random_crop'])\n",
        "val_data_object.replay_buffer.crop_control(parse_dict['random_crop'])\n",
        "\n",
        "# dataloader\n",
        "train_dataloader = DataLoader(data_object.replay_buffer, batch_size = parse_dict['batch_size'], shuffle = True)\n",
        "val_dataloader = DataLoader(val_data_object.replay_buffer, batch_size = parse_dict['batch_size'], shuffle = True)\n",
        "\n",
        "\n",
        "\n",
        "test_info = [0.001,0.005,0.01,0.05,0.1,0.5,1]\n",
        "tests = len(test_info) + 1\n",
        "#tests = 1 \n",
        "\n",
        "#Training loop\n",
        "\n",
        "for i in range(tests):\n",
        "    print(i)\n",
        "    if i >0:\n",
        "\t#parse_dict['encoder_tau'] = np.random.uniform(1e-4,1e-2)\n",
        "        #parse_dict['dynamics_update_freq'] = np.random.uniform(1e-3,1e-2)\n",
        "\n",
        "        #parse_dict['dynamics_update_freq'] = test_info[i-1]\n",
        "        custom_name = 'Contrastive_hp_testing_dynamics-' +str(parse_dict['dynamics_update_freq'])\n",
        "        wandb.init(entity=\"nerdk312\",name=custom_name, project=\"Embed_2_Contrast_dynamics_update_rate_tests\",config = parse_dict)\n",
        "\n",
        "    agent = make_agent(\n",
        "    obs_shape = data_object.obs_shape,\n",
        "    device =data_object.device,\n",
        "    dict_info = parse_dict\n",
        "    )\n",
        "\n",
        "    pretrain_model_name = 'Contrastive' +'_' + data_object.ts\n",
        "    dynamics_model_name = 'Dynamics' +'_' + data_object.ts\n",
        "\n",
        "    early_stopping_contrastive = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=pretrain_model_name)\n",
        "    early_stopping_dynamics = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=dynamics_model_name)\n",
        "\n",
        "    for step in range(parse_dict['num_train_epochs']):\n",
        "        if early_stopping_contrastive.early_stop or early_stopping_dynamics.early_stop: #  Stops the training if early stopping counter is hit\n",
        "            break\n",
        "        agent.update(train_dataloader,val_dataloader,early_stopping_contrastive,early_stopping_dynamics)\n",
        "\n",
        "    wandb.join()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "for i in range(tests):  \n",
        "    print(i)  \n",
        "    if i >0:\n",
        "        #parse_dict['encoder_tau'] = np.random.uniform(1e-4,1e-2)\n",
        "        #parse_dict['encoder_lr'] = np.random.uniform(1e-3,1e-2)\n",
        "        parse_dict['random_jitter'] = True \n",
        "        parse_dict['encoder_tau'] = test_info[i-1]\n",
        "        custom_name = 'Contrastive_hp_testing_random_jitter-'+str(parse_dict['random_jitter']) + '_encoder_tau-' +str(parse_dict['encoder_tau']) \n",
        "        wandb.init(entity=\"nerdk312\",name=custom_name, project=\"Contrastive_learning\",config = parse_dict)\n",
        "\n",
        "    agent = make_agent(\n",
        "    obs_shape = data_object.obs_shape,\n",
        "    device =data_object.device,\n",
        "    dict_info = parse_dict\n",
        "    )\n",
        "\n",
        "    pretrain_model_name = 'Contrastive' +'_' + data_object.ts\n",
        "    dynamics_model_name = 'Dynamics' +'_' + data_object.ts\n",
        "\n",
        "    early_stopping_contrastive = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=pretrain_model_name)\n",
        "    early_stopping_dynamics = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=dynamics_model_name)\n",
        "\n",
        "    for step in range(parse_dict['num_train_epochs']):\n",
        "        if early_stopping_contrastive.early_stop or early_stopping_dynamics.early_stop: #  Stops the training if early stopping counter is hit\n",
        "            break    \n",
        "        agent.update(train_dataloader,val_dataloader,early_stopping_contrastive,early_stopping_dynamics)\n",
        "\n",
        "    wandb.join()\n",
        "'''\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/nerdk312/Embed2Contrast\" target=\"_blank\">https://app.wandb.ai/nerdk312/Embed2Contrast</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/nerdk312/Embed2Contrast/runs/ki1dk93v\" target=\"_blank\">https://app.wandb.ai/nerdk312/Embed2Contrast/runs/ki1dk93v</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n",
            "trajectory number: 0\n",
            "trajectory number: 0\n",
            "0\n",
            "epoch: 1\n",
            "Validation loss decreased/improved for Contrastive_20-05_14:21  (100000000000.000000 --> 6.780341).  Saving model ...\n",
            "Validation loss decreased/improved for Dynamics_20-05_14:21  (100000000000.000000 --> 7.064348).  Saving model ...\n",
            "epoch: 2\n",
            "EarlyStopping for Contrastive_20-05_14:21 counter: 1 out of 3\n",
            "Validation loss decreased/improved for Dynamics_20-05_14:21  (7.064348 --> 6.788999).  Saving model ...\n",
            "epoch: 3\n",
            "EarlyStopping for Contrastive_20-05_14:21 counter: 2 out of 3\n",
            "EarlyStopping for Dynamics_20-05_14:21 counter: 1 out of 3\n",
            "epoch: 4\n",
            "EarlyStopping for Contrastive_20-05_14:21 counter: 3 out of 3\n",
            "Contrastive_20-05_14:21 has stopped\n",
            "EarlyStopping for Dynamics_20-05_14:21 counter: 2 out of 3\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/nerdk312/Embed_2_Contrast_dynamics_update_rate_tests\" target=\"_blank\">https://app.wandb.ai/nerdk312/Embed_2_Contrast_dynamics_update_rate_tests</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/nerdk312/Embed_2_Contrast_dynamics_update_rate_tests/runs/yfs57tuf\" target=\"_blank\">https://app.wandb.ai/nerdk312/Embed_2_Contrast_dynamics_update_rate_tests/runs/yfs57tuf</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "Validation loss decreased/improved for Contrastive_20-05_14:21  (100000000000.000000 --> 28.308090).  Saving model ...\n",
            "Validation loss decreased/improved for Dynamics_20-05_14:21  (100000000000.000000 --> 4.997063).  Saving model ...\n",
            "epoch: 2\n",
            "Validation loss decreased/improved for Contrastive_20-05_14:21  (28.308090 --> 13.767324).  Saving model ...\n",
            "EarlyStopping for Dynamics_20-05_14:21 counter: 1 out of 3\n",
            "epoch: 3\n",
            "Validation loss decreased/improved for Contrastive_20-05_14:21  (13.767324 --> 8.107104).  Saving model ...\n",
            "EarlyStopping for Dynamics_20-05_14:21 counter: 2 out of 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2edb2b9d604a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping_contrastive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mearly_stopping_dynamics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#  Stops the training if early stopping counter is hit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_contrastive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_dynamics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6a4c8dcfd800>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_dataloader, val_dataloader, early_stopper_contrastive, early_stopper_dynamics)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_cpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_anchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid -  Performs the contrastive loss I believe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopper_contrastive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopper_dynamics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_cpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_anchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-6a4c8dcfd800>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(self, dataloader, early_stopper_contrastive, early_stopper_dynamics)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mz_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCURL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_anchor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid -  Encode the anchor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mz_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCURL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid- Encode the positive with the momentum encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCURL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  Nawid- Compute the logits between them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Embed_2_Contrast/models.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x, detach, ema)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mz_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mz_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Embed_2_Contrast/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, detach)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid - Performs conv layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Embed_2_Contrast/encoder.py\u001b[0m in \u001b[0;36mforward_conv\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m#f5 = self.conv_encoder[0:-1](obs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mf5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid -Uses the output of the third layer and then sees whether we want to downsample or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#self.conv_encoder[-1](f5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 539\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m max_pool2d = boolean_dispatch(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_4qJNzfsBRT",
        "colab_type": "code",
        "outputId": "7b8a98b7-6d03-4722-a71a-a73c1feed3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "agent = make_agent(\n",
        "            obs_shape = data_object.obs_shape,\n",
        "            device =data_object.device,\n",
        "            dict_info = parse_dict\n",
        "        )\n",
        "\n",
        "agent.Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dynamics_model(\n",
              "  (encoder): Encoder(\n",
              "    (layer1): Sequential(\n",
              "      (0): Conv2dSame(\n",
              "        (net): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (2): ReLU()\n",
              "      (3): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): ReLU()\n",
              "      (5): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Conv2dSame(\n",
              "        (net): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (2): ReLU()\n",
              "      (3): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): ReLU()\n",
              "      (5): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Conv2dSame(\n",
              "        (net): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (2): ReLU()\n",
              "      (3): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): ReLU()\n",
              "      (5): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Conv2dSame(\n",
              "        (net): Sequential(\n",
              "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (2): ReLU()\n",
              "      (3): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): ReLU()\n",
              "      (5): ResidualBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (1): ReLU()\n",
              "          (2): Conv2dSame(\n",
              "            (net): Sequential(\n",
              "              (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_linear): Linear(in_features=512, out_features=50, bias=True)\n",
              "    (ln): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
              "    (flatten): Flatten()\n",
              "  )\n",
              "  (trunk): Sequential(\n",
              "    (0): Linear(in_features=54, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (output_linear): Linear(in_features=256, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcQy9Gd8dAQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_info = (0.005), (0.01), (0.08), (0.01)\n",
        "#test_info = (10),(20),(50),(100),(200),(500)\n",
        "tests = len(test_info) + 1\n",
        "test_info[0]\n",
        "#parse_dict['dynamics_update_freq'] = test_info[0][0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtD9K4s3HFw7",
        "colab_type": "text"
      },
      "source": [
        "# Old code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JeHblECHRgq",
        "colab_type": "text"
      },
      "source": [
        "Data - Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40FWfGPr3EXj",
        "colab_type": "code",
        "outputId": "d0161775-1879-4f10-b21f-65030e1c35ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "initial_time = time.time()\n",
        "data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity_1'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    data_object.replay_buffer.load(preloaded_train_data_1)\n",
        "else:\n",
        "    data_object.gather_random_trajectories(5000)\n",
        "\n",
        "final_time = time.time() - initial_time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "trajectory number: 0\n",
            "trajectory number: 10\n",
            "trajectory number: 20\n",
            "trajectory number: 30\n",
            "trajectory number: 40\n",
            "trajectory number: 50\n",
            "trajectory number: 60\n",
            "trajectory number: 70\n",
            "trajectory number: 80\n",
            "trajectory number: 90\n",
            "trajectory number: 100\n",
            "trajectory number: 110\n",
            "trajectory number: 120\n",
            "trajectory number: 130\n",
            "trajectory number: 140\n",
            "trajectory number: 150\n",
            "trajectory number: 160\n",
            "trajectory number: 170\n",
            "trajectory number: 180\n",
            "trajectory number: 190\n",
            "trajectory number: 200\n",
            "trajectory number: 210\n",
            "trajectory number: 220\n",
            "trajectory number: 230\n",
            "trajectory number: 240\n",
            "trajectory number: 250\n",
            "trajectory number: 260\n",
            "trajectory number: 270\n",
            "trajectory number: 280\n",
            "trajectory number: 290\n",
            "trajectory number: 300\n",
            "trajectory number: 310\n",
            "trajectory number: 320\n",
            "trajectory number: 330\n",
            "trajectory number: 340\n",
            "trajectory number: 350\n",
            "trajectory number: 360\n",
            "trajectory number: 370\n",
            "trajectory number: 380\n",
            "trajectory number: 390\n",
            "trajectory number: 400\n",
            "trajectory number: 410\n",
            "trajectory number: 420\n",
            "trajectory number: 430\n",
            "trajectory number: 440\n",
            "trajectory number: 450\n",
            "trajectory number: 460\n",
            "trajectory number: 470\n",
            "trajectory number: 480\n",
            "trajectory number: 490\n",
            "trajectory number: 500\n",
            "trajectory number: 510\n",
            "trajectory number: 520\n",
            "trajectory number: 530\n",
            "trajectory number: 540\n",
            "trajectory number: 550\n",
            "trajectory number: 560\n",
            "trajectory number: 570\n",
            "trajectory number: 580\n",
            "trajectory number: 590\n",
            "trajectory number: 600\n",
            "trajectory number: 610\n",
            "trajectory number: 620\n",
            "trajectory number: 630\n",
            "trajectory number: 640\n",
            "trajectory number: 650\n",
            "trajectory number: 660\n",
            "trajectory number: 670\n",
            "trajectory number: 680\n",
            "trajectory number: 690\n",
            "trajectory number: 700\n",
            "trajectory number: 710\n",
            "trajectory number: 720\n",
            "trajectory number: 730\n",
            "trajectory number: 740\n",
            "trajectory number: 750\n",
            "trajectory number: 760\n",
            "trajectory number: 770\n",
            "trajectory number: 780\n",
            "trajectory number: 790\n",
            "trajectory number: 800\n",
            "trajectory number: 810\n",
            "trajectory number: 820\n",
            "trajectory number: 830\n",
            "trajectory number: 840\n",
            "trajectory number: 850\n",
            "trajectory number: 860\n",
            "trajectory number: 870\n",
            "trajectory number: 880\n",
            "trajectory number: 890\n",
            "trajectory number: 900\n",
            "trajectory number: 910\n",
            "trajectory number: 920\n",
            "trajectory number: 930\n",
            "trajectory number: 940\n",
            "trajectory number: 950\n",
            "trajectory number: 960\n",
            "trajectory number: 970\n",
            "trajectory number: 980\n",
            "trajectory number: 990\n",
            "trajectory number: 1000\n",
            "trajectory number: 1010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LrwrqiJOHld",
        "colab_type": "code",
        "outputId": "32a3c23d-80a0-4406-e07d-d93d8202fea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_object.replay_buffer.obses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 100, 100, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43mOgDBl3VCD",
        "colab_type": "code",
        "outputId": "e43ed390-d092-49bb-9dfa-830155550830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data_object_2 = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity_2'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    data_object_2.replay_buffer.load(preloaded_train_data_2)\n",
        "else:\n",
        "    data_object_2.gather_random_trajectories(5000)\n",
        "\n",
        "data_object.replay_buffer.obses = np.concatenate((data_object.replay_buffer.obses, data_object_2.replay_buffer.obses), axis=0)\n",
        "data_object.replay_buffer.actions = np.concatenate((data_object.replay_buffer.actions, data_object_2.replay_buffer.actions), axis=0)\n",
        "data_object.replay_buffer.state_changes = np.concatenate((data_object.replay_buffer.state_changes, data_object_2.replay_buffer.state_changes), axis=0)\n",
        "del data_object_2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "trajectory number: 0\n",
            "trajectory number: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmXktIst3vdm",
        "colab_type": "code",
        "outputId": "cfdf7b56-306d-4398-f9dd-1a9a83b8a8fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_object_3 = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict,parse_dict['train_capacity_3'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    data_object_3.replay_buffer.load(preloaded_train_data_2)\n",
        "else:\n",
        "    data_object_3.gather_random_trajectories(5000)\n",
        "\n",
        "data_object.replay_buffer.obses = np.concatenate((data_object.replay_buffer.obses, data_object_3.replay_buffer.obses), axis=0)\n",
        "data_object.replay_buffer.actions = np.concatenate((data_object.replay_buffer.actions, data_object_3.replay_buffer.actions), axis=0)\n",
        "data_object.replay_buffer.state_changes = np.concatenate((data_object.replay_buffer.state_changes, data_object_3.replay_buffer.state_changes), axis=0)\n",
        "\n",
        "del data_object_3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "trajectory number: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQqnUf9c4qAe",
        "colab_type": "code",
        "outputId": "62626e33-1740-41c1-9dd7-e3a1fb0bb968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "val_data_object = Data_collection(ENV_NAME,n_actions,possible_positions, parse_dict, parse_dict['val_capacity'])\n",
        "if parse_dict['load_trajectories']:\n",
        "    val_data_object.replay_buffer.load(preloaded_val_data)\n",
        "else:\n",
        "    val_data_object.gather_random_trajectories(5000)\n",
        "\n",
        "train_dataloader = DataLoader(data_object.replay_buffer, batch_size = 256, shuffle = True)\n",
        "val_dataloader = DataLoader(val_data_object.replay_buffer, batch_size = 256, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "trajectory number: 0\n",
            "trajectory number: 10\n",
            "trajectory number: 20\n",
            "trajectory number: 30\n",
            "trajectory number: 40\n",
            "trajectory number: 50\n",
            "trajectory number: 60\n",
            "trajectory number: 70\n",
            "trajectory number: 80\n",
            "trajectory number: 90\n",
            "trajectory number: 100\n",
            "trajectory number: 110\n",
            "trajectory number: 120\n",
            "trajectory number: 130\n",
            "trajectory number: 140\n",
            "trajectory number: 150\n",
            "trajectory number: 160\n",
            "trajectory number: 170\n",
            "trajectory number: 180\n",
            "trajectory number: 190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1t5IVqd0rz-",
        "colab_type": "code",
        "outputId": "0cce4aa4-a28e-477c-ae61-8186b49f0ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "agent = make_agent(\n",
        "        obs_shape = data_object.obs_shape,\n",
        "        device =data_object.device,\n",
        "        dict_info = parse_dict\n",
        "    )\n",
        "\n",
        "dyn_model_name = 'Dynamics'+ '_' + data_object.ts\n",
        "pretrain_model_name = 'Contrastive' +'_' + data_object.ts\n",
        "\n",
        "early_stopping_dynamics = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=dyn_model_name)\n",
        "early_stopping_contrastive = EarlyStopping_loss(patience=3, verbose=True, wandb=wandb, name=pretrain_model_name)\n",
        "env = gym.make(ENV_NAME)\n",
        "env = custom_wrapper(env, grayscale = parse_dict['grayscale'])\n",
        "obs = env.reset()\n",
        "info_labels = env.labels()\n",
        "state = data_object.state_conversion(info_labels)\n",
        "\n",
        "\n",
        "if parse_dict['pretrain_model']:\n",
        "    for pretrain_step in range(num_pretrain_steps):\n",
        "        if early_stopping_contrastive.early_stop: #  Stops the training if early stopping counter is hit\n",
        "            break\n",
        "        agent.pretrain(train_dataloader,val_dataloader, early_stopping_contrastive)\n",
        "\n",
        "\n",
        "for step in range(parse_dict['num_train_steps']):\n",
        "    if early_stopping_dynamics.early_stop: #  Stops the training if early stopping counter is hit\n",
        "        break    \n",
        "    agent.update(train_dataloader,val_dataloader,early_stopping_dynamics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "val prediction: tensor([[-7.5782e-01,  6.3639e-01,  2.7453e+00,  1.6735e-01],\n",
            "        [ 2.1720e-01, -6.0008e-01,  2.7503e+00,  7.5085e-02],\n",
            "        [ 8.9513e-02,  1.0737e+00,  2.8843e+00,  2.1094e-01],\n",
            "        [-9.6177e-01,  2.3771e+00,  2.9850e+00,  2.9699e-01],\n",
            "        [-4.8269e-02,  4.9470e-01,  2.8341e+00, -3.1386e-02],\n",
            "        [ 8.3307e-02,  3.8426e-03, -2.4567e+00,  2.5947e-01],\n",
            "        [ 7.1103e-01,  1.2564e+00,  1.7838e-01, -3.4542e+00],\n",
            "        [-8.3351e-01,  1.6868e+00,  2.9461e+00,  2.2221e-01],\n",
            "        [-1.2171e+00,  1.2245e-01, -2.6939e+00,  1.5920e-01],\n",
            "        [ 2.3942e-01,  7.3075e-01,  2.3275e-01,  4.2219e+00],\n",
            "        [ 4.6087e-01,  1.5841e+00, -2.4413e+00,  2.6704e-01],\n",
            "        [ 2.3502e-01,  1.6857e+00,  2.2717e+00,  6.4601e-04],\n",
            "        [ 2.2103e-01,  2.3592e+00,  2.5964e+00, -7.9499e-02],\n",
            "        [ 2.8328e-01, -2.2833e-01, -2.9107e+00, -7.1508e-02],\n",
            "        [-4.4191e-01,  1.6260e+00,  2.7798e+00,  4.2085e-01],\n",
            "        [-6.1588e-02,  2.2736e+00, -2.5601e+00,  5.4287e-01],\n",
            "        [-9.0381e-01, -1.4944e+00, -2.6551e+00,  2.5434e-01],\n",
            "        [-3.5139e-01,  2.1932e+00,  2.6887e+00,  2.1818e-01],\n",
            "        [ 3.2034e-01,  1.1559e+00, -2.4119e+00,  4.1839e-01],\n",
            "        [-3.6887e-01,  5.3852e-01,  2.4492e+00, -2.6389e-02]])\n",
            "state change: tensor([[-3.,  0.,  2.,  0.],\n",
            "        [ 0., -2.,  3.,  0.],\n",
            "        [ 2.,  0.,  3.,  0.],\n",
            "        [ 0., -2.,  3.,  0.],\n",
            "        [ 3.,  0.,  3.,  0.],\n",
            "        [-2., -1., -3.,  0.],\n",
            "        [ 0.,  4.,  0., -4.],\n",
            "        [ 0.,  4.,  3.,  0.],\n",
            "        [-3.,  0., -2.,  0.],\n",
            "        [ 3.,  0.,  0.,  4.],\n",
            "        [ 2.,  0., -3.,  0.],\n",
            "        [ 0.,  3.,  3.,  0.],\n",
            "        [-3.,  0.,  3.,  0.],\n",
            "        [ 0., -3., -3.,  0.],\n",
            "        [-3.,  0.,  2.,  0.],\n",
            "        [ 0.,  4., -3.,  0.],\n",
            "        [ 0., -4., -3.,  0.],\n",
            "        [ 0.,  3.,  3.,  0.],\n",
            "        [ 3.,  0., -3.,  0.],\n",
            "        [ 0., -4.,  2.,  0.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-be1c1b6d5604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping_dynamics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#  Stops the training if early stopping counter is hit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_dynamics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-4aa6f714a593>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_dataloader, val_dataloader, early_stopper)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdyn_update_freq\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_dynamics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate_change\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4aa6f714a593>\u001b[0m in \u001b[0;36mupdate_dynamics\u001b[0;34m(self, obs, actions, labels)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetach_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_encoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gradient not backpropagated to the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mprediction_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Dynamics Training loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mprediction_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  Need to use .item otherwise the loss will still be kept which will reduce the memory on the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Contrastive_loss_Pacman/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, aux, detach_encoder)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetach_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Join vectors along this dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Contrastive_loss_Pacman/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, detach)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nawid - Performs conv layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Contrastive_loss_Pacman/encoder.py\u001b[0m in \u001b[0;36mforward_conv\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#h = conv.view(conv.size(0), -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiM3VOqI5Y9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}